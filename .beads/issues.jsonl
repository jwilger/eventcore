{"id":"eventcore-002","content_hash":"16c7369b52457acc1d3444dc2f2fe22129f9d6b74979570b2d2768a250200a12","title":"Automatic Retry with Sensible Defaults","description":"Add automatic retry on version conflicts so developers don't have to handle ConcurrencyError manually. Use hardcoded sensible defaults (5 retries, exponential backoff with jitter) that work for most cases.","design":"**Retry Logic**: Hardcoded exponential backoff (10ms, 20ms, 40ms, 80ms, 160ms), max 5 attempts, jitter to prevent thundering herd\n**Observability**: Basic logging of retry attempts and outcomes\n**Behavior**: ConcurrencyError triggers automatic retry instead of being returned to developer","acceptance_criteria":"Feature: Developer benefits from automatic retry without configuration\n\nScenario: Developer executes command under contention\n  Given developer creates executor (no retry configuration needed)\n  When version conflict occurs during command execution\n  Then executor automatically retries up to 5 times\n  And uses exponential backoff (10ms, 20ms, 40ms, 80ms, 160ms)\n  And eventually succeeds if conflict resolves\n  And developer never sees ConcurrencyError for transient conflicts\n\nScenario: Developer observes retry attempts in logs\n  Given developer enables logging\n  When version conflict triggers retry\n  Then log shows \"Retry attempt 1/5 for stream account-123 after 10ms\"\n  And subsequent retries log with increasing delays\n  And final log shows success: \"Command succeeded after 3 retry attempts\"\n\nScenario: Developer experiences automatic success under typical contention\n  Given two concurrent commands modify same stream\n  When both commands read stream at version 5\n  And first command writes successfully, advancing to version 6\n  And second command detects conflict\n  Then second command automatically retries\n  And reads stream at version 6\n  And writes successfully at version 7\n  And developer code doesn't handle retry manually\n\nScenario: Retries are exhausted under extreme contention\n  Given command faces continuous conflicts\n  When all 5 retry attempts fail\n  Then ConcurrencyError is returned to developer\n  And error message explains \"Exhausted 5 retry attempts\"\n  And developer can handle this edge case explicitly\n\nScenario: Jitter prevents thundering herd\n  Given 10 concurrent commands conflict on same stream\n  When all commands retry simultaneously\n  Then jitter adds random delay (±20% of backoff)\n  And commands retry at slightly different times\n  And reduces probability of repeated conflicts","notes":"## Testing Approach (2025-10-29)\n\n### Integration Tests (Library Consumer POV)\nTwo end-to-end scenarios testable from developer perspective:\n\n1. **Contention Resolved (Happy Path)**\n   - Given: Version conflict occurs during command execution\n   - When: execute() is called\n   - Then: Command automatically retries and succeeds\n   - Assertion: result.is_ok() - developer never sees ConcurrencyError\n   - Implementation: Use ControlledEventStore (from eventcore-001) to inject single conflict\n\n2. **Retries Exhausted (Max Attempts)**\n   - Given: Persistent conflicts (5+ failures)\n   - When: execute() is called\n   - Then: All 5 retry attempts exhausted\n   - Assertion: matches!(result, Err(CommandError::ConcurrencyError)) with retry context\n   - Implementation: ControlledEventStore injects conflicts on all attempts\n\n### Unit Tests (Implementation Details)\nThree lower-level tests for retry mechanics:\n\n3. **Backoff Timing**\n   - Verify exponential progression: 10ms, 20ms, 40ms, 80ms, 160ms\n   - Test at unit level (not integration test timing)\n\n4. **Jitter Randomness**\n   - Verify jitter adds ±20% random variation to backoff delays\n   - Prevents thundering herd\n   - Test at unit level\n\n5. **Logging Output**\n   - Verify log format: \"Retry attempt N/5 for stream X after Yms\"\n   - Verify final outcome logged\n   - Test as aspect of integration tests (not separate scenario)\n\n### Implementation Order\n1. Start with integration test #1 (contention resolved - simplest)\n2. Implement retry logic to make it pass\n3. Add integration test #2 (retries exhausted)\n4. Add unit tests #3-5 as needed during implementation\n\n### Key Insight\nLogging and jitter are cross-cutting concerns, not separate acceptance criteria.\nFocus on two core behaviors: retry succeeds OR retry exhausts.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.383583474-07:00","updated_at":"2025-11-07T12:03:19.142096551-08:00","closed_at":"2025-11-01T21:06:42.595768583-07:00","source_repo":"."}
{"id":"eventcore-003","content_hash":"e73ccd2977636b3d2184c617c9962202241cc4a07792f4116e7e1ff63d9a6480","title":"Configurable Retry Policies","description":"Enable library consumers to customize retry behavior for their specific workloads and observe retry patterns through metrics and tracing. RetryPolicy configuration with custom max attempts, backoff strategies, and advanced observability.","design":"**RetryPolicy Configuration**: Method chaining API for custom configuration, configurable max_retries and backoff strategies (Exponential with jitter, Fixed delay)\n**Testing Utilities**: RetryPolicy with max_retries(0) for disabling retry in tests, ConflictNTimesStore helper for deterministic conflict injection\n**Observability**: Consider metrics, tracing, and structured logging for retry operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer customizes retry behavior for deployment environment\n\nScenario: Developer uses default retry policy\n  Given developer creates executor without explicit RetryPolicy\n  When version conflict occurs\n  Then executor uses defaults from I-002 (5 attempts, exponential backoff)\n  And developer benefits from sensible defaults without configuration\n\nScenario: Developer configures custom max attempts\n  Given developer creates RetryPolicy::builder().max_attempts(10).build()\n  When developer creates executor with custom policy\n  Then executor retries up to 10 times on conflicts\n  And backoff strategy remains exponential (default)\n\nScenario: Developer configures linear backoff\n  Given developer creates RetryPolicy::builder().backoff_strategy(Linear).build()\n  When version conflict triggers retry\n  Then executor uses linear backoff (10ms, 20ms, 30ms, 40ms...)\n  And developer can tune for predictable timing\n\nScenario: Developer disables retry for testing\n  Given developer creates RetryPolicy::builder().max_attempts(0).build()\n  When version conflict occurs\n  Then executor fails immediately without retry\n  And test can verify conflict detection logic\n\nScenario: Developer observes retry metrics\n  Given developer integrates with Prometheus metrics\n  When commands execute under contention\n  Then metrics track retry_attempts_total, retry_success_after_n_attempts\n  And developer can monitor production contention patterns\n\nScenario: Developer uses distributed tracing\n  Given developer enables tracing integration\n  When version conflict triggers retry\n  Then each retry attempt creates span with context\n  And correlation ID links retries to original command\n  And developer can diagnose contention across services","status":"closed","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-22T09:59:52.635170763-07:00","updated_at":"2025-11-07T12:03:28.57335506-08:00","closed_at":"2025-11-07T11:54:17.742063079-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-003","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:52.645026809-07:00","created_by":"daemon"}]}
{"id":"eventcore-004","content_hash":"8545f113d1028284db9a83b6dd93868c95b4b451f74440d14ce4eb9c03b136a0","title":"Multi-Stream Atomic Commands","description":"Enable library consumers to create commands that atomically read from and write to multiple event streams - THE core value proposition of EventCore. Commands declare multiple streams, read from all declared streams, and write to multiple streams atomically with all-or-nothing semantics.","design":"**Multi-Stream Support**: Commands declare multiple stream IDs, executor reads all declared streams, state reconstruction from events across multiple streams, atomic write to all streams with per-stream version checking\n**Enhanced InMemoryEventStore**: Atomic append across multiple streams, version checking for all streams in single operation, all-or-nothing guarantee\n**Example**: TransferMoney command demonstrating atomic debit/credit\n**Observability**: Consider metrics, tracing, and structured logging for multi-stream operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer creates atomic multi-stream commands\n\nScenario: Developer executes successful multi-stream transfer\n  Given account A exists with balance 100 cents\n  And account B exists with balance 50 cents\n  When developer calls execute(TransferMoney { from: A, to: B, amount: 30 }, store)\n  Then execute() returns Ok(ExecutionResponse)\n  And reading account A events shows final balance of 70 cents\n  And reading account B events shows final balance of 80 cents\n  And both account versions incremented by exactly 1\n\nScenario: Developer observes atomic rollback on version conflict\n  Given account A at version 5 with balance 100\n  And account B at version 3 with balance 50\n  And concurrent command modifies account B advancing version to 4\n  When developer executes TransferMoney(from: A, to: B, amount: 30)\n  Then execute() returns Ok(ExecutionResponse) after automatic retry\n  And account A shows debit event at version 6\n  And account B shows credit event at version 5 (after conflict resolution)\n  And no events exist at the conflicted versions\n\nScenario: Developer verifies no partial state visibility\n  Given two TransferMoney commands execute concurrently on overlapping accounts\n  When both commands attempt to write simultaneously\n  Then one command succeeds with both events written atomically\n  And other command detects conflict and retries automatically\n  And at any point reading both streams shows either both events or neither event\n  And never shows debit without corresponding credit","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.878747571-07:00","updated_at":"2025-11-08T15:28:21.132727584-08:00","closed_at":"2025-11-08T15:28:21.132727584-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-004","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:52.890959478-07:00","created_by":"daemon"}]}
{"id":"eventcore-005","content_hash":"992296600c4c34e18edd0097d9465b8744d707f1f588eb5c06162ff35e2658be","title":"PostgreSQL Production Backend","description":"Enable library consumers to use production-ready PostgreSQL storage with ACID transactions for multi-stream atomicity. Separate eventcore-postgres crate implementing EventStore trait.","design":"**PostgreSQL Adapter**: Separate crate implementing EventStore trait, connection pooling (sqlx), ACID transaction support, JSON event serialization, schema migrations\n**Event Schema**: Events table with UUID primary keys, stream ID/version with unique constraint, JSONB event type/data/metadata, timestamp tracking, optimized indexes\n**Integration Tests**: Real PostgreSQL tests via Docker Compose, multi-stream atomicity with ACID, concurrent command tests\n**Observability**: Consider metrics, tracing, and structured logging for database operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer deploys EventCore with PostgreSQL backend\n\nScenario: Developer connects to PostgreSQL\n  Given developer has PostgreSQL connection string\n  When developer creates PostgresEventStore::new(connection_string)\n  Then connection pool is established\n  And connection is verified with ping\n\nScenario: Developer runs schema migrations\n  Given developer has fresh PostgreSQL database\n  When developer runs eventcore-postgres migrations\n  Then events table is created with correct schema\n  And indexes are created for query performance\n\nScenario: Developer stores events in PostgreSQL\n  Given developer executes command with PostgresEventStore\n  When command writes events to multiple streams\n  Then events are stored in PostgreSQL events table\n  And stream versions increment atomically\n  And event data is serialized as JSON\n\nScenario: Developer verifies ACID atomicity\n  Given developer executes multi-stream command\n  When PostgreSQL transaction commits\n  Then all events across all streams are visible\n  And if transaction rolls back, no events are visible\n  And partial writes are impossible\n\nScenario: Developer handles concurrent commands in production\n  Given multiple application instances execute commands\n  When commands conflict on stream versions\n  Then PostgreSQL detects conflicts via unique constraint\n  And ConcurrencyError is returned to executor\n  And automatic retry resolves conflict\n\nScenario: Developer migrates schema safely\n  Given production PostgreSQL with existing events\n  When developer adds new metadata column\n  Then migration is backward compatible\n  And existing events remain queryable\n  And documentation explains migration strategy","status":"in_progress","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-22T09:59:53.147969784-07:00","updated_at":"2025-12-01T15:45:15.381076042-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-005","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.160209793-07:00","created_by":"daemon"},{"issue_id":"eventcore-005","depends_on_id":"eventcore-1","type":"blocks","created_at":"2025-10-29T12:31:06.583961977-07:00","created_by":"jwilger"}]}
{"id":"eventcore-006","content_hash":"125eeca64470b391d611cac71a6ed898f94cf9eb11d7327b98a81ef548d04fa7","title":"Command Derive Macro","description":"Eliminate infrastructure boilerplate by auto-generating CommandStreams trait implementation from #[stream] field attributes. Developers use #[derive(Command)] to generate all infrastructure code, leaving only domain logic to implement.","design":"**Procedural Macro**: Separate eventcore-macros crate with proc-macro, #[derive(Command)] generates CommandStreams trait, #[stream] field attribute marks stream fields, phantom types for compile-time stream access control\n**Developer Experience**: Before ~30 lines infrastructure, after ~5 lines with derive, focus only on apply/handle methods\n**Testing**: Macro expansion tests with trybuild, integration tests comparing macro vs manual implementation\n**Observability**: Consider metrics, tracing, and structured logging for macro-generated code (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer eliminates boilerplate with derive macro\n\nScenario: Developer uses macro for single-stream command\n  Given developer defines command struct with #[stream] field\n  When developer adds #[derive(Command)]\n  Then CommandStreams trait is implemented automatically\n  And developer only writes apply() and handle() methods\n  And generated code matches hand-written implementation\n\nScenario: Developer uses macro for multi-stream command\n  Given developer defines TransferMoney with two #[stream] fields\n  When developer derives Command\n  Then both stream IDs are extracted automatically\n  And developer writes only business logic\n\nScenario: Developer gets clear compile error for missing attribute\n  Given developer forgets #[stream] attribute on stream field\n  When developer attempts to compile\n  Then compiler produces clear error\n  And error message suggests adding #[stream] attribute\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on derived command\n  When macro expands to Rust code\n  Then generated code is readable and understandable\n  And no unexpected or magic code is generated\n  And expansion matches hand-written CommandStreams trait impl\n\nScenario: Developer migrates from manual to macro\n  Given developer has working command with manual trait impl\n  When developer adds #[derive(Command)] and removes manual impl\n  Then command behaves identically\n  And all tests pass without changes\n  And code is significantly shorter (fewer lines)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.39983429-07:00","updated_at":"2025-11-29T13:30:28.088880441-08:00","closed_at":"2025-11-29T13:30:28.088880441-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-006","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.412440986-07:00","created_by":"daemon"}]}
{"id":"eventcore-007","content_hash":"7a5c535f2761fb8ff3ab5d558eefba97e83a816f62e3e77c30abbd0feb50e14d","title":"Dynamic Stream Discovery","description":"Enable commands to discover additional streams at runtime based on state, supporting workflows where stream requirements depend on runtime data. StreamResolver trait allowing commands to examine initial state and declare additional streams with full atomicity maintained.","design":"**StreamResolver Trait**: Optional trait for commands with state-dependent streams, resolve_additional_streams(state) method, executor support for multi-pass discovery, incremental re-reading optimization\n**Discovery Integration**: Static streams declared with #[stream], dynamic streams discovered via resolver, all streams participate in atomicity, deduplication prevents re-reading same stream\n**Example**: ProcessPayment command discovering payment method streams\n**Observability**: Consider metrics, tracing, and structured logging for dynamic stream discovery (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer discovers streams based on runtime state\n\nScenario: Developer implements stream resolver\n  Given developer creates ProcessPayment command with #[stream] order\n  When developer implements StreamResolver trait\n  Then resolve_additional_streams() examines order state\n  And returns payment method stream IDs based on state\n\nScenario: Developer executes command with discovery\n  Given ProcessPayment command reads order stream\n  And order.payment_method is CreditCard(\"card-123\")\n  When resolver discovers credit card stream\n  Then executor reads credit card stream\n  And apply() receives events from both order and credit card streams\n  And handle() can emit to both streams atomically\n\nScenario: Developer benefits from incremental reading\n  Given command requires multiple discovery passes\n  When second pass discovers new streams\n  Then static streams are read incrementally (only new events)\n  And newly discovered streams are read from version 0\n  And performance is optimized (minimal redundant I/O)\n\nScenario: Developer chooses appropriate strategy\n  Given developer reviews decision framework documentation\n  When developer evaluates stream requirements\n  Then documentation explains when to use static (known at compile time)\n  And when to use dynamic (runtime-dependent)\n  And when to use hybrid (mix of static and dynamic)\n  And examples show each pattern with trade-offs\n\nScenario: Developer verifies atomicity with discovery\n  Given command discovers streams dynamically\n  When executor writes events\n  Then ALL streams (static + discovered) participate in version checking\n  And atomicity is guaranteed across all streams\n  And concurrent modification of any stream triggers retry","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.677539911-07:00","updated_at":"2025-11-30T12:32:33.801677409-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-007","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.68792184-07:00","created_by":"daemon"},{"issue_id":"eventcore-007","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:53.689909474-07:00","created_by":"daemon"}]}
{"id":"eventcore-008","content_hash":"26182ae1c1336a49a626df3fad8a8f970442e31fc8e57fe2cc5427d5f8d542dc","title":"Basic Event Subscriptions","description":"Enable developers to subscribe to event streams and process events in order. Core subscription mechanism WITHOUT checkpointing (eventcore-009 adds that). EventSubscription trait allowing consumers to subscribe to streams and process events using poll-based or callback-based approach.","design":"**EventSubscription Trait**: subscribe(stream_ids) method returning event iterator/stream, delivers events in stream order, works with PostgreSQL and in-memory backends\n**Subscription Features**: Subscribe to one or more streams with pattern matching, process events to build read models, events delivered in order within each stream\n**Example**: AccountBalance projection showing simple read model (not restart-safe yet)\n**Observability**: Consider metrics, tracing, and structured logging for subscription operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer subscribes to event streams\n\nScenario: Developer subscribes to stream pattern\n  Given developer creates subscription to \"account-*\" streams\n  When events are appended to matching streams\n  Then subscription delivers events in order\n  And developer processes events to update read model\n\nScenario: Developer processes events from multiple streams\n  Given developer creates AccountBalance projection\n  When developer subscribes to all account streams\n  Then events from all matching streams are delivered\n  And developer can update balance for each account\n\nScenario: Developer iterates over events\n  Given subscription to account streams\n  When developer calls next() on event stream\n  Then events are returned in order\n  And developer can process synchronously or asynchronously\n\nScenario: Subscription starts fresh without checkpoint\n  Given developer restarts application\n  When developer creates subscription again\n  Then subscription starts from beginning (or current position)\n  And no checkpoint restoration occurs (comes in I-009)\n  And developer understands limitation documented","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.969674847-07:00","updated_at":"2025-11-07T12:04:20.33975901-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-008","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:53.979602684-07:00","created_by":"daemon"}]}
{"id":"eventcore-009","content_hash":"b637be7af9bafd3841664778e89e38c1b0dbfd8c752bb83916bccea49179f2e3","title":"Checkpointing for Subscriptions","description":"Add checkpoint storage and resume capability to subscriptions, enabling reliable projection rebuilding and restart safety. Checkpoint persistence allowing subscriptions to resume from last processed position after restart, making projections production-ready.","design":"**Checkpoint Storage**: save_checkpoint(subscription_id, position) method, load_checkpoint(subscription_id) returns last saved position, checkpoint stored alongside events, automatic checkpoint advancement\n**Resume from Checkpoint**: On restart load last checkpoint, events delivered from checkpoint position + 1, projection rebuilds only new events\n**Projection Rebuilding**: Reset checkpoint to version 0 for complete rebuild, replay all historical events\n**Observability**: Consider metrics, tracing, and structured logging for checkpoint operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer uses checkpoints for reliable projections\n\nScenario: Developer saves checkpoint during processing\n  Given subscription has processed events up to version 1000\n  When developer calls save_checkpoint()\n  Then checkpoint is persisted at version 1000\n  And checkpoint storage confirms save\n\nScenario: Developer resumes from checkpoint after restart\n  Given subscription checkpoint exists at version 1000\n  When application restarts and creates subscription\n  Then subscription loads checkpoint\n  And events are delivered starting from version 1001\n  And projection continues from last known state\n\nScenario: Developer rebuilds projection from scratch\n  Given subscription has existing checkpoint at version 5000\n  When developer resets checkpoint to version 0\n  Then subscription replays ALL historical events\n  And projection is rebuilt completely\n  And new read model is correct\n\nScenario: Developer manages multiple independent projections\n  Given developer creates AccountBalance and AuditLog projections\n  When both subscribe to account streams\n  Then each projection has independent checkpoint\n  And projections can evolve at different rates\n  And one projection can rebuild without affecting others\n\nScenario: Developer handles checkpoint failure gracefully\n  Given checkpoint storage is temporarily unavailable\n  When save_checkpoint() is called\n  Then error is returned (not panic)\n  And developer can retry or fall back to manual tracking","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:54.244346703-07:00","updated_at":"2025-11-07T12:04:29.203462136-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-009","depends_on_id":"eventcore-008","type":"blocks","created_at":"2025-10-22T09:59:54.254509733-07:00","created_by":"daemon"}]}
{"id":"eventcore-010","content_hash":"9d4efd404784c28b1e255b36b246bebcbea46a8d7b07aacc629e053a77a2640e","title":"Chaos Testing Infrastructure","description":"Enable robust testing by injecting failures (read errors, write errors, version conflicts) into in-memory store. Chaos mode for InMemoryEventStore allowing developers to test error handling paths systematically.","design":"**Chaos Configuration**: Configurable failure injection rates, read failures/write failures/version conflict injection, deterministic chaos for reproducible tests\n**Observability**: Consider metrics, tracing, and structured logging for chaos testing (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer tests robustness with chaos injection\n\nScenario: Developer injects read failures\n  Given developer enables chaos mode with 50% read failure rate\n  When executor attempts to read stream\n  Then 50% of reads fail with EventStoreError\n  And developer verifies error handling works correctly\n\nScenario: Developer injects version conflicts\n  Given developer enables conflict injection\n  When executor attempts write\n  Then ConcurrencyError is returned\n  And retry logic is exercised\n  And test verifies eventual success after retries","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.516254533-07:00","updated_at":"2025-12-01T13:07:18.205471052-08:00","closed_at":"2025-12-01T13:07:18.205471052-08:00","source_repo":"."}
{"id":"eventcore-011","content_hash":"313bf17418679374c3214dd279793df0c714f3eab23e48e0d703fc12f473e185","title":"Performance Benchmarking Suite","description":"Establish performance baselines and track regressions using Criterion.rs benchmarks. Comprehensive benchmark suite measuring throughput, latency, and memory usage for key operations.","design":"**Benchmark Suite**: Single-stream command execution, multi-stream command execution, event append throughput, state reconstruction performance, PostgreSQL vs in-memory comparison\n**Criterion.rs**: Reports ops/sec, latency percentiles (P50, P95, P99), results stored for regression tracking\n**Observability**: Consider metrics, tracing, and structured logging for benchmark operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer tracks performance characteristics\n\nScenario: Developer runs benchmark suite\n  Given benchmark suite with representative commands\n  When developer runs cargo bench\n  Then benchmarks report ops/sec, latency percentiles (P50, P95, P99)\n  And results are stored for regression tracking\n\nScenario: Developer detects performance regression\n  Given baseline benchmarks from previous version\n  When code change affects performance\n  Then benchmark fails if regression exceeds threshold (e.g., 10%)\n  And developer is alerted to investigate","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.806895386-07:00","updated_at":"2025-11-07T12:04:40.372632068-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-011","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:54.818896767-07:00","created_by":"daemon"},{"issue_id":"eventcore-011","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:54.820992753-07:00","created_by":"daemon"}]}
{"id":"eventcore-012","content_hash":"ec7d314d9cb5323d52477fd25ea2b74c653316110b133849e41c87c2021c4ada","title":"Snapshot Support for Performance","description":"Optimize state reconstruction for long-lived streams by periodically saving snapshots and starting reconstruction from snapshot instead of version 0. Comes AFTER eventcore-011 because we need performance data to determine if snapshots are necessary and what snapshot frequency makes sense.","design":"**SnapshotStore Trait**: save_snapshot(stream_id, version, state) method, load_snapshot(stream_id) returns (version, state), snapshots stored alongside events, automatic snapshot creation at configurable intervals\n**Executor Integration**: Check for snapshot before reading events, if snapshot exists start from snapshot version, apply only events after snapshot\n**Benchmark-Driven**: Use eventcore-011 benchmark data to determine optimal snapshot frequency\n**Observability**: Consider metrics, tracing, and structured logging for snapshot operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer optimizes long-lived streams with snapshots\n\nScenario: Developer uses benchmark data to decide on snapshots\n  Given developer reviews I-011 benchmark results\n  When stream reconstruction time exceeds threshold (e.g., 100ms for 10k events)\n  Then developer enables snapshot support\n  And chooses snapshot frequency based on performance data\n\nScenario: Developer creates snapshot of stream\n  Given account stream has 10,000 events\n  When snapshot is saved at version 10,000\n  Then snapshot stores complete account state\n  And snapshot size is documented\n\nScenario: Developer loads state from snapshot\n  Given snapshot exists at version 10,000\n  When command reads account stream\n  Then executor loads snapshot as starting state\n  And applies only events 10,001+ (incremental)\n  And state reconstruction is dramatically faster\n\nScenario: Developer configures snapshot frequency\n  Given developer sets snapshot interval to 1000 events (from benchmark guidance)\n  When events are appended\n  Then snapshots are created automatically at 1000, 2000, 3000...\n  And reconstruction remains fast even for very old streams\n\nScenario: Developer measures snapshot impact\n  Given developer runs benchmarks with and without snapshots\n  When comparing reconstruction time for 50k event stream\n  Then snapshot-enabled reconstruction is significantly faster\n  And benchmark documents improvement (e.g., 500ms → 50ms)","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:55.082406342-07:00","updated_at":"2025-11-07T12:04:51.12631679-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-012","depends_on_id":"eventcore-011","type":"blocks","created_at":"2025-10-22T09:59:55.094589257-07:00","created_by":"daemon"}]}
{"id":"eventcore-013","content_hash":"70799701624c58f6b5ee0adcb080163911fc74edeb1ccdaaa57b053984dc1c7a","title":"require! Macro","description":"Provide ergonomic macro for business rule validation with early return, making validation code concise and readable. require! macro that checks conditions and returns CommandError::BusinessRuleViolation on failure. Simpler than emit! (just generates early return with error).","design":"**require! Macro**: Simple condition checking with early return, returns CommandError::BusinessRuleViolation on failure, descriptive error messages from validation expressions, format string support\n**Implementation**: Declarative macro (not proc-macro), expands to if !condition { return Err(...) }, works in any function returning Result\u003c_, CommandError\u003e\n**Observability**: Consider metrics, tracing, and structured logging for business rule violations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer validates business rules with require! macro\n\nScenario: Developer validates simple condition\n  Given developer checks account balance against withdrawal amount\n  When developer uses require!(balance \u003e= amount, \"Insufficient funds\")\n  Then condition is checked at runtime\n  And failure returns CommandError::BusinessRuleViolation\n  And error message is \"Insufficient funds\"\n\nScenario: Developer uses format args in error message\n  Given developer validates with context\n  When developer uses require!(balance \u003e= amount, \"Insufficient: have {}, need {}\", balance, amount)\n  Then error message includes actual values\n  And error is actionable for debugging\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on require! usage\n  When macro expands to Rust code\n  Then generated code is simple if/return pattern\n  And no unexpected magic occurs\n\nScenario: Developer migrates from manual validation\n  Given developer has manual if/return validation\n  When developer replaces with require! macro\n  Then code is more concise (1 line vs 3-5 lines)\n  And behavior is identical\n  And error handling unchanged","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.382858264-07:00","updated_at":"2025-11-29T21:41:45.220807744-08:00","closed_at":"2025-11-29T21:41:45.220807744-08:00","source_repo":"."}
{"id":"eventcore-014","content_hash":"2e0bba0bc4ac5edc6c3b49bd0968fcd112e49c79505a437f6e3cf4d7fe37e53f","title":"emit! Macro","description":"Provide type-safe event emission macro with compile-time verification that events are emitted to declared streams. emit! macro that works with phantom types from derive macro to provide compile-time safety. More complex than require! - must work with phantom types generated by #[derive(Command)].","design":"**emit! Macro**: Compile-time verification that stream is declared in command, works with phantom types from #[derive(Command)], concise syntax for event emission, IDE autocomplete support\n**Type Safety**: Phantom types ensure events only emitted to declared streams, compile error if emitting to undeclared stream\n**Integration**: Works with phantom types from derive macro, stream names from derive macro available to emit! macro\n**Observability**: Consider metrics, tracing, and structured logging for event emission (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer emits events with type safety\n\nScenario: Developer emits event to declared stream\n  Given command declares stream \"account\" with #[stream]\n  When developer uses emit!(ctx, self.account_id, AccountDebited { amount })\n  Then event is emitted to correct stream\n  And code is concise and readable\n  And type checker verifies stream is declared via phantom types produced by #[derive(Command)]\n\nScenario: Developer gets compile error for undeclared stream\n  Given command declares only \"account\" stream\n  When developer attempts emit!(ctx, self.other_id, SomeEvent {})\n  Then code fails to compile\n  And error message explains \"other_id is not a declared stream\"\n  And error suggests adding #[stream] attribute\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on emit! usage\n  When macro expands to Rust code\n  Then generated code calls context.emit() with correct parameters\n  And phantom types enforce compile-time checking\n\nScenario: Developer benefits from IDE autocomplete\n  Given developer types emit!(ctx, self.\n  When IDE autocomplete activates\n  Then only declared stream fields are suggested\n  And developer cannot accidentally emit to wrong stream","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.698240824-07:00","updated_at":"2025-11-30T12:02:31.040480453-08:00","closed_at":"2025-11-30T12:02:31.040480453-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-014","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:55.717324222-07:00","created_by":"daemon"}]}
{"id":"eventcore-015","content_hash":"69793ad1cb195f4e163478c98c49f989cff1e2dc36553e8f78c4dd5206304f3c","title":"Documentation Completeness Audit","description":"Audit and ensure completeness, consistency, and quality of documentation written incrementally throughout eventcore-001 to eventcore-014. NOT 'write all documentation at the end' - each increment includes its own documentation. This ensures documentation is complete, consistent across increments, and ready for library release.","design":"**Completeness Audit**: Verify each increment has Getting Started section, check API docs completeness, ensure examples directory has working code\n**Consistency Audit**: Terminology consistency, code style consistency in examples, accurate cross-references\n**Quality Audit**: Can new developer implement first command in \u003c30 min? Are common issues documented? Are concepts explained for newcomers?","acceptance_criteria":"Feature: Documentation is complete and consistent\n\nScenario: Audit reveals documentation completeness\n  Given auditor reviews all increments I-001 to I-014\n  When checking for documentation coverage\n  Then each increment has Getting Started section\n  And all public APIs have doc comments with examples\n  And examples/ directory has working code for each feature\n  And troubleshooting guide covers all error types\n\nScenario: Audit ensures terminology consistency\n  Given auditor reviews all documentation\n  When checking terminology usage\n  Then \"stream\" is used consistently (not mixing with \"event stream\")\n  And code examples follow consistent style\n  And cross-references are accurate and up-to-date\n\nScenario: New developer validates onboarding quality\n  Given developer has no EventCore experience\n  When developer follows Getting Started guide\n  Then developer implements first command in under 30 minutes\n  And finds answers to common questions in docs\n  And successfully deploys to production using deployment guide\n\nScenario: Audit identifies and fills gaps\n  Given auditor reviews documentation against requirements\n  When gaps are identified (missing examples, unclear explanations)\n  Then gaps are documented and prioritized\n  And critical gaps are filled before release\n  And minor gaps are tracked for future improvement","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:55.9972299-07:00","updated_at":"2025-11-07T12:05:18.973115045-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-015","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:56.009464365-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-003","type":"blocks","created_at":"2025-10-22T09:59:56.01170298-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:56.013797658-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:56.015716896-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:56.017720808-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-007","type":"blocks","created_at":"2025-10-22T09:59:56.019802867-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-008","type":"blocks","created_at":"2025-10-22T09:59:56.021853841-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-009","type":"blocks","created_at":"2025-10-22T09:59:56.023919626-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-010","type":"blocks","created_at":"2025-10-22T09:59:56.025929586-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-011","type":"blocks","created_at":"2025-10-22T09:59:56.027865114-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-012","type":"blocks","created_at":"2025-10-22T09:59:56.029888021-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-013","type":"blocks","created_at":"2025-10-22T09:59:56.031987839-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-014","type":"blocks","created_at":"2025-10-22T09:59:56.034210146-07:00","created_by":"daemon"}]}
{"id":"eventcore-016","content_hash":"8df9735e6b68924730210166af3966661c6beca541fc74de3aad110a75472098","title":"Error Message Consistency Audit","description":"Audit and ensure consistency, clarity, and actionability of error messages written incrementally throughout eventcore-001 to eventcore-014. NOT 'add error messages at the end' - error quality is foundational from eventcore-001. This ensures error messages are consistent in format, provide appropriate context, and are actionable across all increments.","design":"**Consistency Audit**: Error message format consistency, error type usage consistency, context inclusion patterns, action suggestion patterns\n**Clarity Audit**: Are error messages understandable? Do messages explain WHAT failed and WHY? Are technical terms explained?\n**Actionability Audit**: Does each error suggest next steps? Are links to documentation included? Do validation errors show actual vs expected values?","acceptance_criteria":"Feature: Error messages are consistent and actionable\n\nScenario: Audit reveals error message consistency\n  Given auditor reviews all error types across I-001 to I-014\n  When checking error message format\n  Then all errors include relevant context (stream IDs, versions)\n  And all errors explain what failed and why\n  And error format is consistent across all increments\n\nScenario: Developer receives actionable error messages\n  Given developer encounters various error scenarios\n  When error is returned\n  Then error message explains what failed\n  And error suggests next steps (retry, increase capacity, fix code)\n  And error includes context for debugging (actual vs expected values)\n\nScenario: Version conflict error provides full context\n  Given concurrent modification causes conflict\n  When developer receives ConcurrencyError\n  Then error includes stream IDs and current/expected versions\n  And error explains \"Automatic retry will reattempt with fresh state\"\n  And error links to concurrency documentation\n\nScenario: Business rule violation includes context\n  Given account has balance 50\n  When developer executes Withdraw with amount 100\n  And business rule \"sufficient funds\" fails in handle()\n  Then CommandError::BusinessRuleViolation is returned\n  And error shows \"Insufficient funds: balance 50, required 100\"\n  And error is actionable for debugging\n\nScenario: Audit identifies and fixes inconsistencies\n  Given auditor reviews all error messages\n  When inconsistencies are found (missing context, unclear wording)\n  Then inconsistencies are documented and prioritized\n  And critical issues are fixed before release\n  And minor issues are tracked for future improvement","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:56.352815929-07:00","updated_at":"2025-11-07T12:05:29.681224927-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-016","depends_on_id":"eventcore-015","type":"blocks","created_at":"2025-10-22T09:59:56.365070485-07:00","created_by":"daemon"}]}
{"id":"eventcore-1","content_hash":"30b865c4442e4f0c3c58ff7c6be72900e4e88c75339d0b31082a949a885c79db","title":"EventStore Contract Test Suite","description":"Provide reusable test suite that EventStore implementors can run against their implementation to verify contract compliance (version conflict detection, basic read/write, etc.) without copy/pasting tests.","design":"**Public Test API**: New `eventcore::testing` module with public test functions\n**Contract Tests**: test_concurrent_version_conflicts, test_basic_read_write, test_stream_isolation\n**Test Domain**: Minimal ContractTestEvent type for generic testing\n**Usage Pattern**: Implementors call test functions with their EventStore instance\n**Documentation**: Clear examples showing how to use in separate crates\n**Optional Enhancement**: Macro-generated test suite for ergonomics","acceptance_criteria":"Feature: EventStore implementor uses contract test suite\n\nScenario 1: Developer tests InMemoryEventStore with contract suite\n- Imports eventcore::testing::event_store_contract_tests\n- Creates InMemoryEventStore instance\n- Calls test_concurrent_version_conflicts(store)\n- Test passes (verifies version conflict detection works)\n- All other contract tests available and documented\n\nScenario 2: Developer discovers their custom EventStore violates contract\n- Implements custom EventStore with naive append (no version checking)\n- Runs test_concurrent_version_conflicts(store)\n- Test FAILS with clear error message\n- Error explains version conflict wasn't detected\n- Developer fixes implementation, test passes\n\nScenario 3: Future PostgreSQL implementor uses contract suite\n- In eventcore-postgres crate tests\n- Imports public test functions\n- Runs full contract suite against PostgreSQL backend\n- All tests pass, contract verified\n- No need to copy/paste or rewrite tests","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-10-29T12:30:04.264036084-07:00","updated_at":"2025-12-01T15:36:53.062520887-08:00","closed_at":"2025-12-01T15:36:53.062520887-08:00","source_repo":"."}
{"id":"eventcore-2","content_hash":"57266195bd91f623247b99e00ea5608eaf64ae86e54b94ac777f1c3761d62ef7","title":"Single-Stream Command End-to-End","description":"Enable library consumer to create and execute a complete single-stream command with validated domain types, proper error handling, and in-memory event storage. Provides working, testable command execution system.","design":"**Domain Types**: StreamId, EventId, CorrelationId, CausationId (nutype)\n**Error Handling**: Structured hierarchy (EventStoreError, CommandError, ValidationError, ConcurrencyError)\n**Storage**: InMemoryEventStore with optimistic concurrency\n**Command System**: CommandStreams and CommandLogic traits (manual, no macro)\n**Executor**: CommandExecutor orchestrating read → apply → handle → write (NO retry)","acceptance_criteria":"Feature: Developer executes complete single-stream command end-to-end\n\nScenario 1: Developer implements and executes bank account command\n- Creates BankAccount command with StreamId using nutype\n- Implements CommandLogic with apply() and handle()\n- Creates InMemoryEventStore\n- Executes Deposit(account_id, amount: 100)\n- Command succeeds\n- AccountDeposited event is stored with correct metadata\n- Developer can read events from the stream\n- Event contains amount of 100\n\nScenario 2: Developer handles business rule violations with proper errors\n- Account has balance of 50\n- Executes Withdraw command with amount 100\n- CommandError::BusinessRuleViolation is returned\n- Error message explains insufficient funds: balance 50, withdrawal 100\n- Error includes context (account_id, current balance, attempted withdrawal)\n- State is reconstructed via apply() to determine current balance\n\nScenario 3: Developer handles version conflict manually\n- Executes two concurrent Deposit commands on same account\n- Both commands read account at version 0\n- First command writes event, advancing to version 1\n- Second command attempts write expecting version 1\n- ConcurrencyError is returned to developer\n- Developer must handle retry manually (or wait for eventcore-002)\n- No automatic retry occurs\n- Developer can inspect error details (expected vs actual version)","status":"closed","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-29T14:18:50.661348377-07:00","updated_at":"2025-11-07T13:16:29.070821784-08:00","closed_at":"2025-11-07T13:16:29.070821784-08:00","source_repo":"."}
{"id":"eventcore-zy4","content_hash":"d0b7d4f4516d97bae43472f179ac0bcd00e703172951015ba6b79057b2e9b2a3","title":"Switch to cargo-nextest for faster test execution","description":"Replace standard cargo test with cargo-nextest across:\n- Local development (AGENTS.md documentation)\n- Pre-commit hooks (.pre-commit-config.yaml)\n- CI workflow (.github/workflows/ci.yml)\n\nBenefits:\n- Faster parallel test execution\n- Better test output formatting\n- Improved failure reporting\n\nDependencies:\n- Add cargo-nextest to dev tooling\n- Update all test invocations\n- Verify compatibility with existing test suite","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-08T16:46:19.317793502-08:00","updated_at":"2025-11-09T22:21:43.665482497-08:00","closed_at":"2025-11-09T22:21:43.665482497-08:00","source_repo":"."}
