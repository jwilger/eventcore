{"id":"eventcore-002","content_hash":"16c7369b52457acc1d3444dc2f2fe22129f9d6b74979570b2d2768a250200a12","title":"Automatic Retry with Sensible Defaults","description":"Add automatic retry on version conflicts so developers don't have to handle ConcurrencyError manually. Use hardcoded sensible defaults (5 retries, exponential backoff with jitter) that work for most cases.","design":"**Retry Logic**: Hardcoded exponential backoff (10ms, 20ms, 40ms, 80ms, 160ms), max 5 attempts, jitter to prevent thundering herd\n**Observability**: Basic logging of retry attempts and outcomes\n**Behavior**: ConcurrencyError triggers automatic retry instead of being returned to developer","acceptance_criteria":"Feature: Developer benefits from automatic retry without configuration\n\nScenario: Developer executes command under contention\n  Given developer creates executor (no retry configuration needed)\n  When version conflict occurs during command execution\n  Then executor automatically retries up to 5 times\n  And uses exponential backoff (10ms, 20ms, 40ms, 80ms, 160ms)\n  And eventually succeeds if conflict resolves\n  And developer never sees ConcurrencyError for transient conflicts\n\nScenario: Developer observes retry attempts in logs\n  Given developer enables logging\n  When version conflict triggers retry\n  Then log shows \"Retry attempt 1/5 for stream account-123 after 10ms\"\n  And subsequent retries log with increasing delays\n  And final log shows success: \"Command succeeded after 3 retry attempts\"\n\nScenario: Developer experiences automatic success under typical contention\n  Given two concurrent commands modify same stream\n  When both commands read stream at version 5\n  And first command writes successfully, advancing to version 6\n  And second command detects conflict\n  Then second command automatically retries\n  And reads stream at version 6\n  And writes successfully at version 7\n  And developer code doesn't handle retry manually\n\nScenario: Retries are exhausted under extreme contention\n  Given command faces continuous conflicts\n  When all 5 retry attempts fail\n  Then ConcurrencyError is returned to developer\n  And error message explains \"Exhausted 5 retry attempts\"\n  And developer can handle this edge case explicitly\n\nScenario: Jitter prevents thundering herd\n  Given 10 concurrent commands conflict on same stream\n  When all commands retry simultaneously\n  Then jitter adds random delay (±20% of backoff)\n  And commands retry at slightly different times\n  And reduces probability of repeated conflicts","notes":"## Testing Approach (2025-10-29)\n\n### Integration Tests (Library Consumer POV)\nTwo end-to-end scenarios testable from developer perspective:\n\n1. **Contention Resolved (Happy Path)**\n   - Given: Version conflict occurs during command execution\n   - When: execute() is called\n   - Then: Command automatically retries and succeeds\n   - Assertion: result.is_ok() - developer never sees ConcurrencyError\n   - Implementation: Use ControlledEventStore (from eventcore-001) to inject single conflict\n\n2. **Retries Exhausted (Max Attempts)**\n   - Given: Persistent conflicts (5+ failures)\n   - When: execute() is called\n   - Then: All 5 retry attempts exhausted\n   - Assertion: matches!(result, Err(CommandError::ConcurrencyError)) with retry context\n   - Implementation: ControlledEventStore injects conflicts on all attempts\n\n### Unit Tests (Implementation Details)\nThree lower-level tests for retry mechanics:\n\n3. **Backoff Timing**\n   - Verify exponential progression: 10ms, 20ms, 40ms, 80ms, 160ms\n   - Test at unit level (not integration test timing)\n\n4. **Jitter Randomness**\n   - Verify jitter adds ±20% random variation to backoff delays\n   - Prevents thundering herd\n   - Test at unit level\n\n5. **Logging Output**\n   - Verify log format: \"Retry attempt N/5 for stream X after Yms\"\n   - Verify final outcome logged\n   - Test as aspect of integration tests (not separate scenario)\n\n### Implementation Order\n1. Start with integration test #1 (contention resolved - simplest)\n2. Implement retry logic to make it pass\n3. Add integration test #2 (retries exhausted)\n4. Add unit tests #3-5 as needed during implementation\n\n### Key Insight\nLogging and jitter are cross-cutting concerns, not separate acceptance criteria.\nFocus on two core behaviors: retry succeeds OR retry exhausts.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.383583474-07:00","updated_at":"2025-11-07T12:03:19.142096551-08:00","closed_at":"2025-11-01T21:06:42.595768583-07:00","source_repo":"."}
{"id":"eventcore-003","content_hash":"e73ccd2977636b3d2184c617c9962202241cc4a07792f4116e7e1ff63d9a6480","title":"Configurable Retry Policies","description":"Enable library consumers to customize retry behavior for their specific workloads and observe retry patterns through metrics and tracing. RetryPolicy configuration with custom max attempts, backoff strategies, and advanced observability.","design":"**RetryPolicy Configuration**: Method chaining API for custom configuration, configurable max_retries and backoff strategies (Exponential with jitter, Fixed delay)\n**Testing Utilities**: RetryPolicy with max_retries(0) for disabling retry in tests, ConflictNTimesStore helper for deterministic conflict injection\n**Observability**: Consider metrics, tracing, and structured logging for retry operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer customizes retry behavior for deployment environment\n\nScenario: Developer uses default retry policy\n  Given developer creates executor without explicit RetryPolicy\n  When version conflict occurs\n  Then executor uses defaults from I-002 (5 attempts, exponential backoff)\n  And developer benefits from sensible defaults without configuration\n\nScenario: Developer configures custom max attempts\n  Given developer creates RetryPolicy::builder().max_attempts(10).build()\n  When developer creates executor with custom policy\n  Then executor retries up to 10 times on conflicts\n  And backoff strategy remains exponential (default)\n\nScenario: Developer configures linear backoff\n  Given developer creates RetryPolicy::builder().backoff_strategy(Linear).build()\n  When version conflict triggers retry\n  Then executor uses linear backoff (10ms, 20ms, 30ms, 40ms...)\n  And developer can tune for predictable timing\n\nScenario: Developer disables retry for testing\n  Given developer creates RetryPolicy::builder().max_attempts(0).build()\n  When version conflict occurs\n  Then executor fails immediately without retry\n  And test can verify conflict detection logic\n\nScenario: Developer observes retry metrics\n  Given developer integrates with Prometheus metrics\n  When commands execute under contention\n  Then metrics track retry_attempts_total, retry_success_after_n_attempts\n  And developer can monitor production contention patterns\n\nScenario: Developer uses distributed tracing\n  Given developer enables tracing integration\n  When version conflict triggers retry\n  Then each retry attempt creates span with context\n  And correlation ID links retries to original command\n  And developer can diagnose contention across services","status":"closed","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-22T09:59:52.635170763-07:00","updated_at":"2025-11-07T12:03:28.57335506-08:00","closed_at":"2025-11-07T11:54:17.742063079-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-003","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:52.645026809-07:00","created_by":"daemon"}]}
{"id":"eventcore-004","content_hash":"8545f113d1028284db9a83b6dd93868c95b4b451f74440d14ce4eb9c03b136a0","title":"Multi-Stream Atomic Commands","description":"Enable library consumers to create commands that atomically read from and write to multiple event streams - THE core value proposition of EventCore. Commands declare multiple streams, read from all declared streams, and write to multiple streams atomically with all-or-nothing semantics.","design":"**Multi-Stream Support**: Commands declare multiple stream IDs, executor reads all declared streams, state reconstruction from events across multiple streams, atomic write to all streams with per-stream version checking\n**Enhanced InMemoryEventStore**: Atomic append across multiple streams, version checking for all streams in single operation, all-or-nothing guarantee\n**Example**: TransferMoney command demonstrating atomic debit/credit\n**Observability**: Consider metrics, tracing, and structured logging for multi-stream operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer creates atomic multi-stream commands\n\nScenario: Developer executes successful multi-stream transfer\n  Given account A exists with balance 100 cents\n  And account B exists with balance 50 cents\n  When developer calls execute(TransferMoney { from: A, to: B, amount: 30 }, store)\n  Then execute() returns Ok(ExecutionResponse)\n  And reading account A events shows final balance of 70 cents\n  And reading account B events shows final balance of 80 cents\n  And both account versions incremented by exactly 1\n\nScenario: Developer observes atomic rollback on version conflict\n  Given account A at version 5 with balance 100\n  And account B at version 3 with balance 50\n  And concurrent command modifies account B advancing version to 4\n  When developer executes TransferMoney(from: A, to: B, amount: 30)\n  Then execute() returns Ok(ExecutionResponse) after automatic retry\n  And account A shows debit event at version 6\n  And account B shows credit event at version 5 (after conflict resolution)\n  And no events exist at the conflicted versions\n\nScenario: Developer verifies no partial state visibility\n  Given two TransferMoney commands execute concurrently on overlapping accounts\n  When both commands attempt to write simultaneously\n  Then one command succeeds with both events written atomically\n  And other command detects conflict and retries automatically\n  And at any point reading both streams shows either both events or neither event\n  And never shows debit without corresponding credit","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.878747571-07:00","updated_at":"2025-11-08T15:28:21.132727584-08:00","closed_at":"2025-11-08T15:28:21.132727584-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-004","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:52.890959478-07:00","created_by":"daemon"}]}
{"id":"eventcore-005","content_hash":"992296600c4c34e18edd0097d9465b8744d707f1f588eb5c06162ff35e2658be","title":"PostgreSQL Production Backend","description":"Enable library consumers to use production-ready PostgreSQL storage with ACID transactions for multi-stream atomicity. Separate eventcore-postgres crate implementing EventStore trait.","design":"**PostgreSQL Adapter**: Separate crate implementing EventStore trait, connection pooling (sqlx), ACID transaction support, JSON event serialization, schema migrations\n**Event Schema**: Events table with UUID primary keys, stream ID/version with unique constraint, JSONB event type/data/metadata, timestamp tracking, optimized indexes\n**Integration Tests**: Real PostgreSQL tests via Docker Compose, multi-stream atomicity with ACID, concurrent command tests\n**Observability**: Consider metrics, tracing, and structured logging for database operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer deploys EventCore with PostgreSQL backend\n\nScenario: Developer connects to PostgreSQL\n  Given developer has PostgreSQL connection string\n  When developer creates PostgresEventStore::new(connection_string)\n  Then connection pool is established\n  And connection is verified with ping\n\nScenario: Developer runs schema migrations\n  Given developer has fresh PostgreSQL database\n  When developer runs eventcore-postgres migrations\n  Then events table is created with correct schema\n  And indexes are created for query performance\n\nScenario: Developer stores events in PostgreSQL\n  Given developer executes command with PostgresEventStore\n  When command writes events to multiple streams\n  Then events are stored in PostgreSQL events table\n  And stream versions increment atomically\n  And event data is serialized as JSON\n\nScenario: Developer verifies ACID atomicity\n  Given developer executes multi-stream command\n  When PostgreSQL transaction commits\n  Then all events across all streams are visible\n  And if transaction rolls back, no events are visible\n  And partial writes are impossible\n\nScenario: Developer handles concurrent commands in production\n  Given multiple application instances execute commands\n  When commands conflict on stream versions\n  Then PostgreSQL detects conflicts via unique constraint\n  And ConcurrencyError is returned to executor\n  And automatic retry resolves conflict\n\nScenario: Developer migrates schema safely\n  Given production PostgreSQL with existing events\n  When developer adds new metadata column\n  Then migration is backward compatible\n  And existing events remain queryable\n  And documentation explains migration strategy","status":"closed","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-22T09:59:53.147969784-07:00","updated_at":"2025-12-03T19:04:47.346811346-08:00","closed_at":"2025-12-03T19:04:47.346811346-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-005","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.160209793-07:00","created_by":"daemon"},{"issue_id":"eventcore-005","depends_on_id":"eventcore-1","type":"blocks","created_at":"2025-10-29T12:31:06.583961977-07:00","created_by":"jwilger"}]}
{"id":"eventcore-006","content_hash":"125eeca64470b391d611cac71a6ed898f94cf9eb11d7327b98a81ef548d04fa7","title":"Command Derive Macro","description":"Eliminate infrastructure boilerplate by auto-generating CommandStreams trait implementation from #[stream] field attributes. Developers use #[derive(Command)] to generate all infrastructure code, leaving only domain logic to implement.","design":"**Procedural Macro**: Separate eventcore-macros crate with proc-macro, #[derive(Command)] generates CommandStreams trait, #[stream] field attribute marks stream fields, phantom types for compile-time stream access control\n**Developer Experience**: Before ~30 lines infrastructure, after ~5 lines with derive, focus only on apply/handle methods\n**Testing**: Macro expansion tests with trybuild, integration tests comparing macro vs manual implementation\n**Observability**: Consider metrics, tracing, and structured logging for macro-generated code (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer eliminates boilerplate with derive macro\n\nScenario: Developer uses macro for single-stream command\n  Given developer defines command struct with #[stream] field\n  When developer adds #[derive(Command)]\n  Then CommandStreams trait is implemented automatically\n  And developer only writes apply() and handle() methods\n  And generated code matches hand-written implementation\n\nScenario: Developer uses macro for multi-stream command\n  Given developer defines TransferMoney with two #[stream] fields\n  When developer derives Command\n  Then both stream IDs are extracted automatically\n  And developer writes only business logic\n\nScenario: Developer gets clear compile error for missing attribute\n  Given developer forgets #[stream] attribute on stream field\n  When developer attempts to compile\n  Then compiler produces clear error\n  And error message suggests adding #[stream] attribute\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on derived command\n  When macro expands to Rust code\n  Then generated code is readable and understandable\n  And no unexpected or magic code is generated\n  And expansion matches hand-written CommandStreams trait impl\n\nScenario: Developer migrates from manual to macro\n  Given developer has working command with manual trait impl\n  When developer adds #[derive(Command)] and removes manual impl\n  Then command behaves identically\n  And all tests pass without changes\n  And code is significantly shorter (fewer lines)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.39983429-07:00","updated_at":"2025-11-29T13:30:28.088880441-08:00","closed_at":"2025-11-29T13:30:28.088880441-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-006","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.412440986-07:00","created_by":"daemon"}]}
{"id":"eventcore-007","content_hash":"7a5c535f2761fb8ff3ab5d558eefba97e83a816f62e3e77c30abbd0feb50e14d","title":"Dynamic Stream Discovery","description":"Enable commands to discover additional streams at runtime based on state, supporting workflows where stream requirements depend on runtime data. StreamResolver trait allowing commands to examine initial state and declare additional streams with full atomicity maintained.","design":"**StreamResolver Trait**: Optional trait for commands with state-dependent streams, resolve_additional_streams(state) method, executor support for multi-pass discovery, incremental re-reading optimization\n**Discovery Integration**: Static streams declared with #[stream], dynamic streams discovered via resolver, all streams participate in atomicity, deduplication prevents re-reading same stream\n**Example**: ProcessPayment command discovering payment method streams\n**Observability**: Consider metrics, tracing, and structured logging for dynamic stream discovery (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer discovers streams based on runtime state\n\nScenario: Developer implements stream resolver\n  Given developer creates ProcessPayment command with #[stream] order\n  When developer implements StreamResolver trait\n  Then resolve_additional_streams() examines order state\n  And returns payment method stream IDs based on state\n\nScenario: Developer executes command with discovery\n  Given ProcessPayment command reads order stream\n  And order.payment_method is CreditCard(\"card-123\")\n  When resolver discovers credit card stream\n  Then executor reads credit card stream\n  And apply() receives events from both order and credit card streams\n  And handle() can emit to both streams atomically\n\nScenario: Developer benefits from incremental reading\n  Given command requires multiple discovery passes\n  When second pass discovers new streams\n  Then static streams are read incrementally (only new events)\n  And newly discovered streams are read from version 0\n  And performance is optimized (minimal redundant I/O)\n\nScenario: Developer chooses appropriate strategy\n  Given developer reviews decision framework documentation\n  When developer evaluates stream requirements\n  Then documentation explains when to use static (known at compile time)\n  And when to use dynamic (runtime-dependent)\n  And when to use hybrid (mix of static and dynamic)\n  And examples show each pattern with trade-offs\n\nScenario: Developer verifies atomicity with discovery\n  Given command discovers streams dynamically\n  When executor writes events\n  Then ALL streams (static + discovered) participate in version checking\n  And atomicity is guaranteed across all streams\n  And concurrent modification of any stream triggers retry","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.677539911-07:00","updated_at":"2025-12-04T22:25:11.0382135-08:00","closed_at":"2025-12-04T22:25:11.0382135-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-007","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:53.68792184-07:00","created_by":"daemon"},{"issue_id":"eventcore-007","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:53.689909474-07:00","created_by":"daemon"}]}
{"id":"eventcore-008","content_hash":"86be5ec8a8a5b5b2a317728777bfc08d22099c17f249220e516e1f5f44fd462f","title":"Basic Event Subscriptions","description":"Enable developers to subscribe to event streams and process events in order. Core subscription mechanism WITHOUT checkpointing (eventcore-009 adds that). EventSubscription trait allowing consumers to subscribe to streams and process events using poll-based or callback-based approach.","design":"**EventSubscription Trait**: subscribe(stream_ids) method returning event iterator/stream, delivers events in stream order, works with PostgreSQL and in-memory backends\n**Subscription Features**: Subscribe to one or more streams with pattern matching, process events to build read models, events delivered in order within each stream\n**Example**: AccountBalance projection showing simple read model (not restart-safe yet)\n**Observability**: Consider metrics, tracing, and structured logging for subscription operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer subscribes to event streams\n\nScenario: Developer subscribes to stream pattern\n  Given developer creates subscription to \"account-*\" streams\n  When events are appended to matching streams\n  Then subscription delivers events in order\n  And developer processes events to update read model\n\nScenario: Developer processes events from multiple streams\n  Given developer creates AccountBalance projection\n  When developer subscribes to all account streams\n  Then events from all matching streams are delivered\n  And developer can update balance for each account\n\nScenario: Developer iterates over events\n  Given subscription to account streams\n  When developer calls next() on event stream\n  Then events are returned in order\n  And developer can process synchronously or asynchronously\n\nScenario: Subscription starts fresh without checkpoint\n  Given developer restarts application\n  When developer creates subscription again\n  Then subscription starts from beginning (or current position)\n  And no checkpoint restoration occurs (comes in I-009)\n  And developer understands limitation documented","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.969674847-07:00","updated_at":"2025-12-06T17:05:53.800894552-08:00","closed_at":"2025-12-06T17:05:53.800894552-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-008","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:53.979602684-07:00","created_by":"daemon"}]}
{"id":"eventcore-009","content_hash":"b637be7af9bafd3841664778e89e38c1b0dbfd8c752bb83916bccea49179f2e3","title":"Checkpointing for Subscriptions","description":"Add checkpoint storage and resume capability to subscriptions, enabling reliable projection rebuilding and restart safety. Checkpoint persistence allowing subscriptions to resume from last processed position after restart, making projections production-ready.","design":"**Checkpoint Storage**: save_checkpoint(subscription_id, position) method, load_checkpoint(subscription_id) returns last saved position, checkpoint stored alongside events, automatic checkpoint advancement\n**Resume from Checkpoint**: On restart load last checkpoint, events delivered from checkpoint position + 1, projection rebuilds only new events\n**Projection Rebuilding**: Reset checkpoint to version 0 for complete rebuild, replay all historical events\n**Observability**: Consider metrics, tracing, and structured logging for checkpoint operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer uses checkpoints for reliable projections\n\nScenario: Developer saves checkpoint during processing\n  Given subscription has processed events up to version 1000\n  When developer calls save_checkpoint()\n  Then checkpoint is persisted at version 1000\n  And checkpoint storage confirms save\n\nScenario: Developer resumes from checkpoint after restart\n  Given subscription checkpoint exists at version 1000\n  When application restarts and creates subscription\n  Then subscription loads checkpoint\n  And events are delivered starting from version 1001\n  And projection continues from last known state\n\nScenario: Developer rebuilds projection from scratch\n  Given subscription has existing checkpoint at version 5000\n  When developer resets checkpoint to version 0\n  Then subscription replays ALL historical events\n  And projection is rebuilt completely\n  And new read model is correct\n\nScenario: Developer manages multiple independent projections\n  Given developer creates AccountBalance and AuditLog projections\n  When both subscribe to account streams\n  Then each projection has independent checkpoint\n  And projections can evolve at different rates\n  And one projection can rebuild without affecting others\n\nScenario: Developer handles checkpoint failure gracefully\n  Given checkpoint storage is temporarily unavailable\n  When save_checkpoint() is called\n  Then error is returned (not panic)\n  And developer can retry or fall back to manual tracking","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:54.244346703-07:00","updated_at":"2025-12-06T17:05:53.901594293-08:00","closed_at":"2025-12-06T17:05:53.901594293-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-009","depends_on_id":"eventcore-008","type":"blocks","created_at":"2025-10-22T09:59:54.254509733-07:00","created_by":"daemon"}]}
{"id":"eventcore-010","content_hash":"9d4efd404784c28b1e255b36b246bebcbea46a8d7b07aacc629e053a77a2640e","title":"Chaos Testing Infrastructure","description":"Enable robust testing by injecting failures (read errors, write errors, version conflicts) into in-memory store. Chaos mode for InMemoryEventStore allowing developers to test error handling paths systematically.","design":"**Chaos Configuration**: Configurable failure injection rates, read failures/write failures/version conflict injection, deterministic chaos for reproducible tests\n**Observability**: Consider metrics, tracing, and structured logging for chaos testing (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer tests robustness with chaos injection\n\nScenario: Developer injects read failures\n  Given developer enables chaos mode with 50% read failure rate\n  When executor attempts to read stream\n  Then 50% of reads fail with EventStoreError\n  And developer verifies error handling works correctly\n\nScenario: Developer injects version conflicts\n  Given developer enables conflict injection\n  When executor attempts write\n  Then ConcurrencyError is returned\n  And retry logic is exercised\n  And test verifies eventual success after retries","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.516254533-07:00","updated_at":"2025-12-01T13:07:18.205471052-08:00","closed_at":"2025-12-01T13:07:18.205471052-08:00","source_repo":"."}
{"id":"eventcore-011","content_hash":"313bf17418679374c3214dd279793df0c714f3eab23e48e0d703fc12f473e185","title":"Performance Benchmarking Suite","description":"Establish performance baselines and track regressions using Criterion.rs benchmarks. Comprehensive benchmark suite measuring throughput, latency, and memory usage for key operations.","design":"**Benchmark Suite**: Single-stream command execution, multi-stream command execution, event append throughput, state reconstruction performance, PostgreSQL vs in-memory comparison\n**Criterion.rs**: Reports ops/sec, latency percentiles (P50, P95, P99), results stored for regression tracking\n**Observability**: Consider metrics, tracing, and structured logging for benchmark operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer tracks performance characteristics\n\nScenario: Developer runs benchmark suite\n  Given benchmark suite with representative commands\n  When developer runs cargo bench\n  Then benchmarks report ops/sec, latency percentiles (P50, P95, P99)\n  And results are stored for regression tracking\n\nScenario: Developer detects performance regression\n  Given baseline benchmarks from previous version\n  When code change affects performance\n  Then benchmark fails if regression exceeds threshold (e.g., 10%)\n  And developer is alerted to investigate","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.806895386-07:00","updated_at":"2025-11-07T12:04:40.372632068-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-011","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:54.818896767-07:00","created_by":"daemon"},{"issue_id":"eventcore-011","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:54.820992753-07:00","created_by":"daemon"}]}
{"id":"eventcore-012","content_hash":"ec7d314d9cb5323d52477fd25ea2b74c653316110b133849e41c87c2021c4ada","title":"Snapshot Support for Performance","description":"Optimize state reconstruction for long-lived streams by periodically saving snapshots and starting reconstruction from snapshot instead of version 0. Comes AFTER eventcore-011 because we need performance data to determine if snapshots are necessary and what snapshot frequency makes sense.","design":"**SnapshotStore Trait**: save_snapshot(stream_id, version, state) method, load_snapshot(stream_id) returns (version, state), snapshots stored alongside events, automatic snapshot creation at configurable intervals\n**Executor Integration**: Check for snapshot before reading events, if snapshot exists start from snapshot version, apply only events after snapshot\n**Benchmark-Driven**: Use eventcore-011 benchmark data to determine optimal snapshot frequency\n**Observability**: Consider metrics, tracing, and structured logging for snapshot operations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer optimizes long-lived streams with snapshots\n\nScenario: Developer uses benchmark data to decide on snapshots\n  Given developer reviews I-011 benchmark results\n  When stream reconstruction time exceeds threshold (e.g., 100ms for 10k events)\n  Then developer enables snapshot support\n  And chooses snapshot frequency based on performance data\n\nScenario: Developer creates snapshot of stream\n  Given account stream has 10,000 events\n  When snapshot is saved at version 10,000\n  Then snapshot stores complete account state\n  And snapshot size is documented\n\nScenario: Developer loads state from snapshot\n  Given snapshot exists at version 10,000\n  When command reads account stream\n  Then executor loads snapshot as starting state\n  And applies only events 10,001+ (incremental)\n  And state reconstruction is dramatically faster\n\nScenario: Developer configures snapshot frequency\n  Given developer sets snapshot interval to 1000 events (from benchmark guidance)\n  When events are appended\n  Then snapshots are created automatically at 1000, 2000, 3000...\n  And reconstruction remains fast even for very old streams\n\nScenario: Developer measures snapshot impact\n  Given developer runs benchmarks with and without snapshots\n  When comparing reconstruction time for 50k event stream\n  Then snapshot-enabled reconstruction is significantly faster\n  And benchmark documents improvement (e.g., 500ms → 50ms)","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:55.082406342-07:00","updated_at":"2025-11-07T12:04:51.12631679-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-012","depends_on_id":"eventcore-011","type":"blocks","created_at":"2025-10-22T09:59:55.094589257-07:00","created_by":"daemon"}]}
{"id":"eventcore-013","content_hash":"70799701624c58f6b5ee0adcb080163911fc74edeb1ccdaaa57b053984dc1c7a","title":"require! Macro","description":"Provide ergonomic macro for business rule validation with early return, making validation code concise and readable. require! macro that checks conditions and returns CommandError::BusinessRuleViolation on failure. Simpler than emit! (just generates early return with error).","design":"**require! Macro**: Simple condition checking with early return, returns CommandError::BusinessRuleViolation on failure, descriptive error messages from validation expressions, format string support\n**Implementation**: Declarative macro (not proc-macro), expands to if !condition { return Err(...) }, works in any function returning Result\u003c_, CommandError\u003e\n**Observability**: Consider metrics, tracing, and structured logging for business rule violations (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer validates business rules with require! macro\n\nScenario: Developer validates simple condition\n  Given developer checks account balance against withdrawal amount\n  When developer uses require!(balance \u003e= amount, \"Insufficient funds\")\n  Then condition is checked at runtime\n  And failure returns CommandError::BusinessRuleViolation\n  And error message is \"Insufficient funds\"\n\nScenario: Developer uses format args in error message\n  Given developer validates with context\n  When developer uses require!(balance \u003e= amount, \"Insufficient: have {}, need {}\", balance, amount)\n  Then error message includes actual values\n  And error is actionable for debugging\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on require! usage\n  When macro expands to Rust code\n  Then generated code is simple if/return pattern\n  And no unexpected magic occurs\n\nScenario: Developer migrates from manual validation\n  Given developer has manual if/return validation\n  When developer replaces with require! macro\n  Then code is more concise (1 line vs 3-5 lines)\n  And behavior is identical\n  And error handling unchanged","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.382858264-07:00","updated_at":"2025-11-29T21:41:45.220807744-08:00","closed_at":"2025-11-29T21:41:45.220807744-08:00","source_repo":"."}
{"id":"eventcore-014","content_hash":"2e0bba0bc4ac5edc6c3b49bd0968fcd112e49c79505a437f6e3cf4d7fe37e53f","title":"emit! Macro","description":"Provide type-safe event emission macro with compile-time verification that events are emitted to declared streams. emit! macro that works with phantom types from derive macro to provide compile-time safety. More complex than require! - must work with phantom types generated by #[derive(Command)].","design":"**emit! Macro**: Compile-time verification that stream is declared in command, works with phantom types from #[derive(Command)], concise syntax for event emission, IDE autocomplete support\n**Type Safety**: Phantom types ensure events only emitted to declared streams, compile error if emitting to undeclared stream\n**Integration**: Works with phantom types from derive macro, stream names from derive macro available to emit! macro\n**Observability**: Consider metrics, tracing, and structured logging for event emission (specific requirements determined during implementation)","acceptance_criteria":"Feature: Developer emits events with type safety\n\nScenario: Developer emits event to declared stream\n  Given command declares stream \"account\" with #[stream]\n  When developer uses emit!(ctx, self.account_id, AccountDebited { amount })\n  Then event is emitted to correct stream\n  And code is concise and readable\n  And type checker verifies stream is declared via phantom types produced by #[derive(Command)]\n\nScenario: Developer gets compile error for undeclared stream\n  Given command declares only \"account\" stream\n  When developer attempts emit!(ctx, self.other_id, SomeEvent {})\n  Then code fails to compile\n  And error message explains \"other_id is not a declared stream\"\n  And error suggests adding #[stream] attribute\n\nScenario: Developer verifies macro expansion\n  Given developer uses cargo expand on emit! usage\n  When macro expands to Rust code\n  Then generated code calls context.emit() with correct parameters\n  And phantom types enforce compile-time checking\n\nScenario: Developer benefits from IDE autocomplete\n  Given developer types emit!(ctx, self.\n  When IDE autocomplete activates\n  Then only declared stream fields are suggested\n  And developer cannot accidentally emit to wrong stream","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.698240824-07:00","updated_at":"2025-11-30T12:02:31.040480453-08:00","closed_at":"2025-11-30T12:02:31.040480453-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-014","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:55.717324222-07:00","created_by":"daemon"}]}
{"id":"eventcore-015","content_hash":"69793ad1cb195f4e163478c98c49f989cff1e2dc36553e8f78c4dd5206304f3c","title":"Documentation Completeness Audit","description":"Audit and ensure completeness, consistency, and quality of documentation written incrementally throughout eventcore-001 to eventcore-014. NOT 'write all documentation at the end' - each increment includes its own documentation. This ensures documentation is complete, consistent across increments, and ready for library release.","design":"**Completeness Audit**: Verify each increment has Getting Started section, check API docs completeness, ensure examples directory has working code\n**Consistency Audit**: Terminology consistency, code style consistency in examples, accurate cross-references\n**Quality Audit**: Can new developer implement first command in \u003c30 min? Are common issues documented? Are concepts explained for newcomers?","acceptance_criteria":"Feature: Documentation is complete and consistent\n\nScenario: Audit reveals documentation completeness\n  Given auditor reviews all increments I-001 to I-014\n  When checking for documentation coverage\n  Then each increment has Getting Started section\n  And all public APIs have doc comments with examples\n  And examples/ directory has working code for each feature\n  And troubleshooting guide covers all error types\n\nScenario: Audit ensures terminology consistency\n  Given auditor reviews all documentation\n  When checking terminology usage\n  Then \"stream\" is used consistently (not mixing with \"event stream\")\n  And code examples follow consistent style\n  And cross-references are accurate and up-to-date\n\nScenario: New developer validates onboarding quality\n  Given developer has no EventCore experience\n  When developer follows Getting Started guide\n  Then developer implements first command in under 30 minutes\n  And finds answers to common questions in docs\n  And successfully deploys to production using deployment guide\n\nScenario: Audit identifies and fills gaps\n  Given auditor reviews documentation against requirements\n  When gaps are identified (missing examples, unclear explanations)\n  Then gaps are documented and prioritized\n  And critical gaps are filled before release\n  And minor gaps are tracked for future improvement","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:55.9972299-07:00","updated_at":"2025-11-07T12:05:18.973115045-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-015","depends_on_id":"eventcore-002","type":"blocks","created_at":"2025-10-22T09:59:56.009464365-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-003","type":"blocks","created_at":"2025-10-22T09:59:56.01170298-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-004","type":"blocks","created_at":"2025-10-22T09:59:56.013797658-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-005","type":"blocks","created_at":"2025-10-22T09:59:56.015716896-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-006","type":"blocks","created_at":"2025-10-22T09:59:56.017720808-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-007","type":"blocks","created_at":"2025-10-22T09:59:56.019802867-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-008","type":"blocks","created_at":"2025-10-22T09:59:56.021853841-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-009","type":"blocks","created_at":"2025-10-22T09:59:56.023919626-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-010","type":"blocks","created_at":"2025-10-22T09:59:56.025929586-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-011","type":"blocks","created_at":"2025-10-22T09:59:56.027865114-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-012","type":"blocks","created_at":"2025-10-22T09:59:56.029888021-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-013","type":"blocks","created_at":"2025-10-22T09:59:56.031987839-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-014","type":"blocks","created_at":"2025-10-22T09:59:56.034210146-07:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-017","type":"blocks","created_at":"2025-12-06T17:28:51.516193802-08:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-018","type":"blocks","created_at":"2025-12-06T17:28:51.624298642-08:00","created_by":"daemon"},{"issue_id":"eventcore-015","depends_on_id":"eventcore-019","type":"blocks","created_at":"2025-12-06T17:28:51.727807087-08:00","created_by":"daemon"}]}
{"id":"eventcore-016","content_hash":"8df9735e6b68924730210166af3966661c6beca541fc74de3aad110a75472098","title":"Error Message Consistency Audit","description":"Audit and ensure consistency, clarity, and actionability of error messages written incrementally throughout eventcore-001 to eventcore-014. NOT 'add error messages at the end' - error quality is foundational from eventcore-001. This ensures error messages are consistent in format, provide appropriate context, and are actionable across all increments.","design":"**Consistency Audit**: Error message format consistency, error type usage consistency, context inclusion patterns, action suggestion patterns\n**Clarity Audit**: Are error messages understandable? Do messages explain WHAT failed and WHY? Are technical terms explained?\n**Actionability Audit**: Does each error suggest next steps? Are links to documentation included? Do validation errors show actual vs expected values?","acceptance_criteria":"Feature: Error messages are consistent and actionable\n\nScenario: Audit reveals error message consistency\n  Given auditor reviews all error types across I-001 to I-014\n  When checking error message format\n  Then all errors include relevant context (stream IDs, versions)\n  And all errors explain what failed and why\n  And error format is consistent across all increments\n\nScenario: Developer receives actionable error messages\n  Given developer encounters various error scenarios\n  When error is returned\n  Then error message explains what failed\n  And error suggests next steps (retry, increase capacity, fix code)\n  And error includes context for debugging (actual vs expected values)\n\nScenario: Version conflict error provides full context\n  Given concurrent modification causes conflict\n  When developer receives ConcurrencyError\n  Then error includes stream IDs and current/expected versions\n  And error explains \"Automatic retry will reattempt with fresh state\"\n  And error links to concurrency documentation\n\nScenario: Business rule violation includes context\n  Given account has balance 50\n  When developer executes Withdraw with amount 100\n  And business rule \"sufficient funds\" fails in handle()\n  Then CommandError::BusinessRuleViolation is returned\n  And error shows \"Insufficient funds: balance 50, required 100\"\n  And error is actionable for debugging\n\nScenario: Audit identifies and fixes inconsistencies\n  Given auditor reviews all error messages\n  When inconsistencies are found (missing context, unclear wording)\n  Then inconsistencies are documented and prioritized\n  And critical issues are fixed before release\n  And minor issues are tracked for future improvement","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:56.352815929-07:00","updated_at":"2025-11-07T12:05:29.681224927-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-016","depends_on_id":"eventcore-015","type":"blocks","created_at":"2025-10-22T09:59:56.365070485-07:00","created_by":"daemon"}]}
{"id":"eventcore-017","content_hash":"a70d3a2cb4b210d83e7f5a01dfdd966b8a5c50a50be319e497adf008f7acdb86","title":"Single-Process Projection Foundation","description":"Implements EventSubscription trait, SubscriptionQuery composable filters, and push-based futures::Stream delivery per the Event Subscriptions \u0026 Projections section of docs/ARCHITECTURE.md. Foundation for building read models and projections in single-process applications.\n\n**Core Components:**\n- EventSubscription trait with subscribe() returning impl Stream\n- SubscriptionQuery with composable filter chain (.filter_stream_prefix(), .filter_event_type::\u003cE\u003e())\n- InMemoryEventStore basic subscription support (non-durable, single-process only)\n- Push-based event delivery via futures::Stream\n\n**Design Decisions (from ARCHITECTURE.md Event Subscriptions \u0026 Projections section):**\n- Separate from EventStore trait (CQRS boundary)\n- Composable filter chain over magic strings or enum variants\n- futures::Stream for native Rust async integration\n- StreamId remains aggregate identity; SubscriptionQuery for cross-cutting queries","acceptance_criteria":"Feature: Developer builds single-process projections\n\nScenario: Developer creates subscription query for stream prefix\n  Given developer imports SubscriptionQuery\n  When developer writes SubscriptionQuery::all().filter_stream_prefix(\"account-\")\n  Then query compiles successfully\n  And IDE autocomplete shows available filter methods\n\nScenario: Developer subscribes to all events\n  Given InMemoryEventStore with events in multiple streams\n  When developer calls subscribe(SubscriptionQuery::all())\n  Then futures::Stream is returned\n  And all events are delivered in EventId (UUIDv7) order\n\nScenario: Developer filters by event type\n  Given subscription to account streams\n  When developer adds .filter_event_type::\u003cMoneyDeposited\u003e()\n  Then only MoneyDeposited events are delivered\n  And other event types are filtered out\n\nScenario: Developer uses StreamExt combinators\n  Given active subscription stream\n  When developer chains .map().filter().take(10)\n  Then standard futures combinators work\n  And events can be collected into Vec\n\nScenario: Developer builds simple read model\n  Given subscription delivering account events\n  When developer folds events into AccountBalance struct\n  Then read model reflects current state\n  And projection updates as new events arrive","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-06T17:27:15.715735863-08:00","updated_at":"2025-12-17T13:36:58.703587656-08:00","closed_at":"2025-12-17T13:36:58.703587656-08:00","source_repo":"."}
{"id":"eventcore-017.1","content_hash":"f26585b7562900b6fc6f9446c11ba99c40d5fcada92d011ba495a7ae6bdbb44c","title":"Add debug logging for broadcast send failures in InMemoryEventStore","description":"Location: src/store.rs:701-704. Broadcast send errors are silently discarded with 'let _ = self.broadcast_tx.send(event)'. Add tracing::debug\\! to log when broadcasts fail.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:43:06.69819848-08:00","updated_at":"2025-12-17T11:41:22.031009263-08:00","closed_at":"2025-12-17T11:41:22.031009263-08:00","source_repo":"."}
{"id":"eventcore-017.10","content_hash":"da6d1cfdfcfb93739e651f13b12f8c0c8e9c1cbb2e319d025618750aaa335ab4","title":"Fix CollectionError::Timeout to report actual received count","description":"Location: eventcore-testing/src/assertions.rs:27-32. Timeout error always reports 'received: 0' regardless of how many events were actually collected. Track and report actual count.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-17T10:43:46.246615665-08:00","updated_at":"2025-12-17T11:44:15.230041267-08:00","closed_at":"2025-12-17T11:44:15.230041267-08:00","source_repo":"."}
{"id":"eventcore-017.11","content_hash":"e5f92295c4e181e75f18621fb66a67b0681eb5d8903f6ed13c61260b10a60e45","title":"Add warning logging when invalid EventTypeName causes event to be skipped","description":"Location: eventcore-postgres/src/lib.rs:377-380. When stored event type name fails validation, event is silently skipped. Add tracing::warn! with the invalid type name and global_sequence.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-17T10:43:46.424526089-08:00","updated_at":"2025-12-17T11:46:37.528786551-08:00","closed_at":"2025-12-17T11:46:37.528786551-08:00","source_repo":"."}
{"id":"eventcore-017.12","content_hash":"4ac5eb0f151d1182c9d8db7b8519a0468cf8ac583e5f904ff35972e7489635ba","title":"Add warning logging when broadcast receiver lags behind","description":"Locations: src/store.rs:956-959, eventcore-postgres/src/lib.rs:531-533. RecvError::Lagged is silently consumed. Add tracing::warn! with skipped event count. Note: comment claims at-least-once but lagging after catchup means events are lost.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-17T10:43:46.630725477-08:00","updated_at":"2025-12-17T11:46:37.547939392-08:00","closed_at":"2025-12-17T11:46:37.547939392-08:00","source_repo":"."}
{"id":"eventcore-017.13","content_hash":"bbcd78081cd61ede02653654eaf081352178d93d39811914d0a47357200d652c","title":"Consider replacing SubscriptionError::Generic(String) with structured variants","description":"Location: src/subscription.rs:128-138. Generic(String) loses error chain information. Consider adding specific variants (DatabaseError, MutexPoisoned) or adding #[source] field to preserve error chain.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-17T10:43:46.816476875-08:00","updated_at":"2025-12-17T11:49:09.398928129-08:00","closed_at":"2025-12-17T11:49:09.398928129-08:00","source_repo":"."}
{"id":"eventcore-017.14","content_hash":"52c5287ada384f87667b9c8765ce0b79705b9b6c21546c25ccdabca35c2aaa3d","title":"Remove outdated '(future)' comment from implemented filter features","description":"Location: src/subscription.rs:43. Comment says '// Composable filters (future)' but filters ARE implemented. Remove the misleading '(future)' note.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-17T10:44:05.672171716-08:00","updated_at":"2025-12-17T11:33:32.285478644-08:00","closed_at":"2025-12-17T11:33:32.285478644-08:00","source_repo":"."}
{"id":"eventcore-017.15","content_hash":"7fd7e4e5da6b28e9f8ced72cb8aac1bea14faca8229a082f102430283d819aba","title":"Add view enum example to Subscribable trait doc comment","description":"Location: src/subscription.rs:140-167. The doc comment could benefit from a brief code example showing the view enum pattern mentioned in ADR-020.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:05.797369794-08:00","updated_at":"2025-12-17T11:39:41.87830765-08:00","closed_at":"2025-12-17T11:39:41.87830765-08:00","source_repo":"."}
{"id":"eventcore-017.16","content_hash":"d386b96d9482dfdc42a5545f9d3926fa0b9aaab51e520878edb153939d37a9f3","title":"Add test for concurrent subscriptions with different filters","description":"Location: tests/I-017-subscription_foundation_test.rs. Current tests use single subscribers. Add test verifying multiple concurrent subscriptions with different filters receive correct events without interference.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:05.921182354-08:00","updated_at":"2025-12-17T11:51:34.592131697-08:00","closed_at":"2025-12-17T11:51:34.592131697-08:00","source_repo":"."}
{"id":"eventcore-017.17","content_hash":"afed42097fb51dd4e89190c24bf3e6fe7ddf14dbea3e87286938222a23c5a073","title":"Add test for lagged subscriber behavior","description":"Location: tests/I-017-subscription_foundation_test.rs. The RecvError::Lagged handling is not explicitly tested. Add test that deliberately lags a subscriber and verifies subscription continues gracefully.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:06.055725741-08:00","updated_at":"2025-12-17T11:51:34.606546441-08:00","closed_at":"2025-12-17T11:51:34.606546441-08:00","source_repo":"."}
{"id":"eventcore-017.18","content_hash":"b52f34688fd0581a8aa98257d4d6cc460d4a144fadf427c053b94ceef95a3799","title":"Add PartialEq, Eq, Display derives to StreamPrefix","description":"Location: src/subscription.rs:22-27. StreamPrefix is missing PartialEq/Eq (limits usability in collections) and Display (limits error message quality). Consider adding these derives.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:06.188930883-08:00","updated_at":"2025-12-17T11:40:04.881169467-08:00","closed_at":"2025-12-17T11:40:04.881169467-08:00","source_repo":"."}
{"id":"eventcore-017.19","content_hash":"aa2d73f872f303fb283807ce57071897f08a7ec5a6301a788a469e22390e06b2","title":"Consider returning \u0026'static [EventTypeName] from subscribable_type_names()","description":"Location: src/subscription.rs:148. Currently returns Vec\u003cEventTypeName\u003e which allocates on every call. For high-throughput scenarios, consider \u0026'static slice or smallvec.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:06.323781491-08:00","updated_at":"2025-12-17T11:57:23.442997238-08:00","closed_at":"2025-12-17T11:57:23.442997238-08:00","source_repo":"."}
{"id":"eventcore-017.2","content_hash":"18fdbefc6962df4682625fefd3076e3679fcadff50acde4da85423b31367ebde","title":"Add debug logging for broadcast send failures in PostgresEventStore","description":"Location: eventcore-postgres/src/lib.rs:235-238. Same pattern as InMemory - broadcast send errors silently discarded. Add tracing::debug! logging.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:43:06.80243553-08:00","updated_at":"2025-12-17T11:41:22.050305737-08:00","closed_at":"2025-12-17T11:41:22.050305737-08:00","source_repo":"."}
{"id":"eventcore-017.20","content_hash":"94af3c30da4f68e8b7d332ebc89e3b2a8d50cf1d643dabda3465a82b0ce8adb3","title":"Log errors in map_sqlx_error before converting to generic StoreFailure","description":"Location: eventcore-postgres/src/lib.rs:597-613. The function discards original error details. Add tracing::error! before returning generic StoreFailure to aid debugging.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-17T10:44:06.481839357-08:00","updated_at":"2025-12-17T11:58:04.850604044-08:00","closed_at":"2025-12-17T11:58:04.850604044-08:00","source_repo":"."}
{"id":"eventcore-017.3","content_hash":"64a4629236c51c213f2a59c73bd032aa4ebff73768e41b172a26b7a772ebacf6","title":"Add warning logging for database poll errors in Postgres subscription","description":"Location: eventcore-postgres/src/lib.rs:583-586. Database poll errors are silently swallowed with 'Err(_) =\u003e continue'. Add tracing::warn\\! to log the error before continuing.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:43:06.91605544-08:00","updated_at":"2025-12-17T11:41:22.063167433-08:00","closed_at":"2025-12-17T11:41:22.063167433-08:00","source_repo":"."}
{"id":"eventcore-017.4","content_hash":"1825ea93b7859abb1bb040ca7a1a31b5bc2dd2fe7ab84479a3a9e29387a968b3","title":"Mark unimplemented Projector/Checkpoint sections in ARCHITECTURE.md as Planned","description":"Location: docs/ARCHITECTURE.md:226-346. The Projector trait and Checkpoint management sections describe features that don't exist yet. Either remove or clearly mark as 'Planned Implementation'.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:43:07.033540353-08:00","updated_at":"2025-12-17T11:35:03.555810334-08:00","closed_at":"2025-12-17T11:35:03.555810334-08:00","source_repo":"."}
{"id":"eventcore-017.5","content_hash":"53ea95c372576e483d9e9988d25283a7ea91413ee425b18d5ddd5f2d97d0403e","title":"Add implementation status note to ADR-016 for unimplemented features","description":"Location: docs/adr/ADR-016-subscription-model.md:141-147. ADR describes ActiveSubscription::checkpoint() and SubscriptionCoordinator which don't exist. Add note clarifying current implementation scope.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-17T10:43:31.413993892-08:00","updated_at":"2025-12-17T11:35:41.896815086-08:00","closed_at":"2025-12-17T11:35:41.896815086-08:00","source_repo":"."}
{"id":"eventcore-017.6","content_hash":"31c6d433cde7e584629e8c8418c873e75d80928b4502b01caeeabe559d3da653","title":"Add implementation status note to ADR-019 for Projector trait","description":"Location: docs/adr/ADR-019-projector-trait.md. The entire Projector trait, FailureContext, FailureStrategy are not implemented. Add status note: 'design ratified; implementation pending'.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-17T10:43:31.550674373-08:00","updated_at":"2025-12-17T11:35:41.906772747-08:00","closed_at":"2025-12-17T11:35:41.906772747-08:00","source_repo":"."}
{"id":"eventcore-017.7","content_hash":"dfdea88d0790b9ea20d9486f9be7d16f7404076386103036a6622356f87ea37a","title":"Fix incorrect doc comment claiming InMemory doesn't implement EventSubscription","description":"Location: src/store.rs:494. Comment states 'It does not implement EventSubscription' but line 826 shows it DOES implement EventSubscription. Remove the incorrect statement.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-17T10:43:31.690892534-08:00","updated_at":"2025-12-17T11:33:04.584111168-08:00","closed_at":"2025-12-17T11:33:04.584111168-08:00","source_repo":"."}
{"id":"eventcore-017.8","content_hash":"0fd4399f591ff40448d6331bf70c412108d7ed8a290c0079723fc3dd9569f0c9","title":"Fix API examples using non-existent filter_event_type::\u003cT\u003e() method","description":"Locations: src/subscription.rs:44-47, docs/ARCHITECTURE.md:137-141. Examples show filter_event_type::\u003cMoneyDeposited\u003e() but actual method is filter_event_type_name(EventTypeName). Update to match actual API.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-17T10:43:45.89756975-08:00","updated_at":"2025-12-17T11:33:32.295451587-08:00","closed_at":"2025-12-17T11:33:32.295451587-08:00","source_repo":"."}
{"id":"eventcore-017.9","content_hash":"390f768cad69ad0e211e69609383f817811201683fda775639584270fa24e7b9","title":"Improve test helper error context in collect_subscription_events","description":"Location: eventcore-testing/src/assertions.rs:22-25. The .expect() loses error context when subscription fails. Include the error in panic message or return Result instead of panicking.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-17T10:43:46.061828113-08:00","updated_at":"2025-12-17T11:44:15.09970723-08:00","closed_at":"2025-12-17T11:44:15.09970723-08:00","source_repo":"."}
{"id":"eventcore-018","content_hash":"e09ab836ff1d8b6df3794d702aec682fff23630568ee864629d6af1b83e4f45f","title":"Distributed Subscription Coordination","description":"Implements SubscriptionCoordinator trait for production horizontal scaling per the Event Subscriptions \u0026 Projections section of docs/ARCHITECTURE.md. Enables multiple processes to coordinate subscription ownership with automatic rebalancing, heartbeat detection, and checkpoint-based ownership validation.\n\n**Core Components:**\n- SubscriptionCoordinator trait with join_group() returning GroupMembership\n- GroupMembership with heartbeat and assignments() stream\n- ActiveSubscription with checkpoint() method for ownership validation\n- AssignmentChange enum (Assigned/Revoked)\n- PostgreSQL implementation using advisory locks\n\n**Design Decisions (from ARCHITECTURE.md Event Subscriptions \u0026 Projections section):**\n- Coordinator separate from EventSubscription (control plane vs data plane)\n- Associated type for type-safe backend capability expression\n- Checkpoint validates ownership AND persists position\n- At-least-once delivery; consumers must be idempotent\n- Checkpoint failure signals subscription revocation","acceptance_criteria":"Feature: Developer deploys horizontally scaled projections\n\nScenario: Developer joins consumer group\n  Given PostgreSQL backend with SubscriptionCoordinator support\n  When developer calls coordinator.join_group(\"my-projection\")\n  Then GroupMembership is returned\n  And heartbeat begins automatically\n\nScenario: Developer receives subscription assignment\n  Given active GroupMembership\n  When coordinator assigns subscription to this process\n  Then assignments() stream yields Assigned(ActiveSubscription)\n  And ActiveSubscription contains event stream and checkpoint method\n\nScenario: Developer checkpoints processed events\n  Given ActiveSubscription processing events\n  When developer calls active.checkpoint(position)\n  Then ownership is validated\n  And position is persisted for resumption\n  And Ok(()) returned if still owner\n\nScenario: Developer discovers revocation via checkpoint\n  Given subscription reassigned to another process during rebalancing\n  When previous owner calls checkpoint()\n  Then Err(Revoked) is returned\n  And consumer knows to stop processing\n\nScenario: Developer handles rebalancing gracefully\n  Given two processes in same consumer group\n  When third process joins group\n  Then coordinator rebalances subscriptions\n  And some subscriptions move to new process\n  And affected consumers discover via checkpoint failure\n\nScenario: Developer resumes from checkpoint after restart\n  Given checkpoint persisted at position 1000\n  When process restarts and rejoins group\n  Then subscription resumes from position 1001\n  And no events are skipped or lost","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-06T17:27:36.97281065-08:00","updated_at":"2025-12-06T17:32:12.304678436-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-018","depends_on_id":"eventcore-017","type":"blocks","created_at":"2025-12-06T17:27:36.974996375-08:00","created_by":"daemon"}]}
{"id":"eventcore-019","content_hash":"665369a3c117bf3ae5a4d5082a0793a1d50c706f9da8a4dd480d1fb1fad77d68","title":"Production Subscription Patterns","description":"Provides production-ready patterns and utilities for building projections per the Event Subscriptions \u0026 Projections section of docs/ARCHITECTURE.md. Includes idempotency helpers, projection templates, and operational tooling.\n\n**Core Components:**\n- Idempotency helpers for at-least-once processing\n- Projection builder utilities\n- Batched checkpoint patterns\n- Dead letter queue support for failed events\n- Observability integration (metrics, tracing)\n\n**Design Decisions (from ARCHITECTURE.md Event Subscriptions \u0026 Projections section):**\n- At-least-once delivery requires consumer idempotency\n- Middleware on EventStream for processing behavior\n- Checkpoint strategies: per-event, batched, timeout-based\n- Operational concerns: monitoring, alerting, debugging","acceptance_criteria":"Feature: Developer builds production-grade projections\n\nScenario: Developer implements idempotent projection\n  Given projection that may receive duplicate events during rebalancing\n  When developer uses EventIdempotencyGuard helper\n  Then duplicate events are detected and skipped\n  And projection state remains consistent\n\nScenario: Developer uses batched checkpointing\n  Given high-throughput projection processing many events\n  When developer configures checkpoint_every(100) or checkpoint_timeout(5s)\n  Then checkpoints occur at configured intervals\n  And checkpoint overhead is amortized\n\nScenario: Developer handles poison events\n  Given event that causes projection to fail repeatedly\n  When developer configures dead_letter_queue()\n  Then problematic event is moved to DLQ after max retries\n  And subscription continues processing remaining events\n  And operator can investigate and replay DLQ events\n\nScenario: Developer monitors projection health\n  Given production projection with tracing enabled\n  When projection processes events\n  Then metrics emitted: events_processed, checkpoint_latency, lag_seconds\n  And traces include correlation_id from event metadata\n  And Grafana/Prometheus dashboards show projection status\n\nScenario: Developer debugs subscription issues\n  Given subscription experiencing high latency\n  When developer queries projection status API\n  Then current position, checkpoint position, and lag are visible\n  And consumer group membership is inspectable\n  And recent errors are surfaced","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-06T17:27:53.997923285-08:00","updated_at":"2025-12-06T17:32:22.848921376-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-019","depends_on_id":"eventcore-018","type":"blocks","created_at":"2025-12-06T17:27:54.00299808-08:00","created_by":"daemon"},{"issue_id":"eventcore-019","depends_on_id":"eventcore-4tk","type":"blocks","created_at":"2025-12-14T11:19:48.907747455-08:00","created_by":"daemon"}]}
{"id":"eventcore-0ex","content_hash":"d586c17e0947ecfb7433ec1563aac805ff62a70f6233d6a60565b0df38acea32","title":"Implement EventSubscription for PostgresEventStore","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-14T23:07:16.790210529-08:00","updated_at":"2025-12-14T23:41:22.478736423-08:00","closed_at":"2025-12-14T23:41:22.478736423-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-0ex","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-14T23:07:16.809084634-08:00","created_by":"daemon"}]}
{"id":"eventcore-0r4","content_hash":"efb4b3ef2bc75db95684b5505093fed786ad5af3484533f95da49dea14d7d64b","title":"Refactor: Improve mutex error context","description":"","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-16T14:49:22.844527718-08:00","updated_at":"2025-12-17T10:17:03.231899627-08:00","closed_at":"2025-12-17T10:17:03.231899627-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-0r4","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:14.434936008-08:00","created_by":"daemon"}]}
{"id":"eventcore-1","content_hash":"30b865c4442e4f0c3c58ff7c6be72900e4e88c75339d0b31082a949a885c79db","title":"EventStore Contract Test Suite","description":"Provide reusable test suite that EventStore implementors can run against their implementation to verify contract compliance (version conflict detection, basic read/write, etc.) without copy/pasting tests.","design":"**Public Test API**: New `eventcore::testing` module with public test functions\n**Contract Tests**: test_concurrent_version_conflicts, test_basic_read_write, test_stream_isolation\n**Test Domain**: Minimal ContractTestEvent type for generic testing\n**Usage Pattern**: Implementors call test functions with their EventStore instance\n**Documentation**: Clear examples showing how to use in separate crates\n**Optional Enhancement**: Macro-generated test suite for ergonomics","acceptance_criteria":"Feature: EventStore implementor uses contract test suite\n\nScenario 1: Developer tests InMemoryEventStore with contract suite\n- Imports eventcore::testing::event_store_contract_tests\n- Creates InMemoryEventStore instance\n- Calls test_concurrent_version_conflicts(store)\n- Test passes (verifies version conflict detection works)\n- All other contract tests available and documented\n\nScenario 2: Developer discovers their custom EventStore violates contract\n- Implements custom EventStore with naive append (no version checking)\n- Runs test_concurrent_version_conflicts(store)\n- Test FAILS with clear error message\n- Error explains version conflict wasn't detected\n- Developer fixes implementation, test passes\n\nScenario 3: Future PostgreSQL implementor uses contract suite\n- In eventcore-postgres crate tests\n- Imports public test functions\n- Runs full contract suite against PostgreSQL backend\n- All tests pass, contract verified\n- No need to copy/paste or rewrite tests","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-10-29T12:30:04.264036084-07:00","updated_at":"2025-12-01T15:36:53.062520887-08:00","closed_at":"2025-12-01T15:36:53.062520887-08:00","source_repo":"."}
{"id":"eventcore-2","content_hash":"57266195bd91f623247b99e00ea5608eaf64ae86e54b94ac777f1c3761d62ef7","title":"Single-Stream Command End-to-End","description":"Enable library consumer to create and execute a complete single-stream command with validated domain types, proper error handling, and in-memory event storage. Provides working, testable command execution system.","design":"**Domain Types**: StreamId, EventId, CorrelationId, CausationId (nutype)\n**Error Handling**: Structured hierarchy (EventStoreError, CommandError, ValidationError, ConcurrencyError)\n**Storage**: InMemoryEventStore with optimistic concurrency\n**Command System**: CommandStreams and CommandLogic traits (manual, no macro)\n**Executor**: CommandExecutor orchestrating read → apply → handle → write (NO retry)","acceptance_criteria":"Feature: Developer executes complete single-stream command end-to-end\n\nScenario 1: Developer implements and executes bank account command\n- Creates BankAccount command with StreamId using nutype\n- Implements CommandLogic with apply() and handle()\n- Creates InMemoryEventStore\n- Executes Deposit(account_id, amount: 100)\n- Command succeeds\n- AccountDeposited event is stored with correct metadata\n- Developer can read events from the stream\n- Event contains amount of 100\n\nScenario 2: Developer handles business rule violations with proper errors\n- Account has balance of 50\n- Executes Withdraw command with amount 100\n- CommandError::BusinessRuleViolation is returned\n- Error message explains insufficient funds: balance 50, withdrawal 100\n- Error includes context (account_id, current balance, attempted withdrawal)\n- State is reconstructed via apply() to determine current balance\n\nScenario 3: Developer handles version conflict manually\n- Executes two concurrent Deposit commands on same account\n- Both commands read account at version 0\n- First command writes event, advancing to version 1\n- Second command attempts write expecting version 1\n- ConcurrencyError is returned to developer\n- Developer must handle retry manually (or wait for eventcore-002)\n- No automatic retry occurs\n- Developer can inspect error details (expected vs actual version)","status":"closed","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-29T14:18:50.661348377-07:00","updated_at":"2025-11-07T13:16:29.070821784-08:00","closed_at":"2025-11-07T13:16:29.070821784-08:00","source_repo":"."}
{"id":"eventcore-26v","content_hash":"21464fb8f3ba17a0c94ff4bde5cbc1090cded6f86073fa6f4a952e175c96d604","title":"Refactor: Extract PostgreSQL query builder","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:15.26678424-08:00","updated_at":"2025-12-16T22:02:42.378240665-08:00","closed_at":"2025-12-16T22:02:42.378240665-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-26v","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:13.939109498-08:00","created_by":"daemon"}]}
{"id":"eventcore-2zn","content_hash":"cd0553ff4363c846c75105dbac28308da1d1ba5c872b01b56245fcb40145c833","title":"ADR: Subscribable trait design rationale","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:22.730296314-08:00","updated_at":"2025-12-17T07:02:35.092199303-08:00","closed_at":"2025-12-17T07:02:35.092199303-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-2zn","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:14.182442078-08:00","created_by":"daemon"}]}
{"id":"eventcore-3s4","content_hash":"764e055d9f71f981a2e5dfd2e4600018118199b2f0a27f551aaa9a2eb190f703","title":"Update InMemoryEventStore to yield deserialization errors instead of skipping","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T11:18:46.554131548-08:00","updated_at":"2025-12-15T11:37:41.206670492-08:00","closed_at":"2025-12-15T11:37:41.206670492-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-3s4","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-14T11:18:46.554876521-08:00","created_by":"daemon"}]}
{"id":"eventcore-4aj","content_hash":"d93ee14b2d7c75029d83c3944b2e62d0f12d7389669390a623ff1b874e4021f8","title":"CRITICAL: Add logging for silent broadcast send failures in PostgresEventStore","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:41:50.081424185-08:00","updated_at":"2025-12-17T10:42:51.501043931-08:00","closed_at":"2025-12-17T10:42:51.501043931-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-4aj","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-17T10:41:50.082502297-08:00","created_by":"daemon"}]}
{"id":"eventcore-4p8","content_hash":"8654d4b8d91d3c591f9773e11f2c652dff676878deacd251a884a3e7088cf17e","title":"Refactor: Create generic assertion helpers in eventcore-testing","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:22.508461428-08:00","updated_at":"2025-12-17T06:55:57.354048325-08:00","closed_at":"2025-12-17T06:55:57.354048325-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-4p8","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:14.059440513-08:00","created_by":"daemon"}]}
{"id":"eventcore-4tk","content_hash":"f90c4212c86b040fd5266cf9dbd42c0948eae3ff2321b78f14cb6e208541d857","title":"Projector Trait for Read Model Construction","description":"Implements the Projector trait for building read model projections per ADR-019.\n\n**Context:**\nADR-019 supersedes ADR-018's middleware approach with a trait-based pattern inspired by Commanded's Event.Handler behaviour. This provides a cohesive abstraction where projection logic, error handling, and lifecycle hooks live in one place.\n\n**Core Components:**\n- Projector trait with project(), on_error(), after_update() callbacks\n- FailureContext struct (event, error, attempt count, stream position)\n- FailureStrategy enum (Fatal, Skip, Retry)\n- run_projector() helper function\n- ProjectorConfig for retry configuration\n\n**Design Decisions (from ADR-019):**\n- Error handling has a clear \"home\" in on_error() callback\n- Fatal is default (safe by default, explicit opt-in to Skip/Retry)\n- Rich context passed to error callback for informed decisions\n- Lifecycle hooks (after_update) for side effects\n- Raw stream access preserved for advanced use cases\n\n**Supersedes:**\nADR-018's middleware-based error handling approach. Core principles (Fatal default, ordering preservation) remain; implementation changes from middleware to trait callbacks.","acceptance_criteria":"Feature: Developer builds projections using Projector trait\n\nScenario: Developer implements basic projector\n  Given developer creates struct implementing Projector trait\n  When developer implements project() method for their event type\n  Then projector processes events from subscription stream\n  And Fatal behavior is default (stops on first error)\n  And no on_error() override required for safe default\n\nScenario: Developer uses Skip strategy via on_error callback\n  Given projector with on_error() returning FailureStrategy::Skip\n  When project() returns an error\n  Then on_error() receives FailureContext with event, error, attempt count\n  And returning Skip acknowledges event and continues to next\n  And projection tolerates gaps in event coverage\n\nScenario: Developer uses Retry strategy with backoff\n  Given projector with on_error() returning FailureStrategy::Retry\n  When project() returns an error\n  Then event is retried with configured delay\n  And attempt count increments in FailureContext\n  And subsequent events wait until current succeeds or exhausts retries\n\nScenario: Retry exhaustion escalates to Fatal\n  Given projector configured with max_retries = 3\n  When event fails on all 3 attempts\n  Then run_projector returns error (Fatal behavior)\n  And no further events are processed\n  And operator can investigate the failure\n\nScenario: Developer uses after_update lifecycle hook\n  Given projector with after_update() implementation\n  When project() succeeds\n  Then after_update() is called with the event\n  And developer can trigger side effects (notifications, metrics)\n\nScenario: Developer uses raw stream for advanced cases\n  Given subscription returning Stream\u003cItem = Result\u003cE, SubscriptionError\u003e\u003e\n  When developer needs custom stream processing\n  Then raw stream access is available without Projector trait\n  And StreamExt combinators work as before\n\nScenario: All strategies preserve temporal ordering\n  Given projector processing events in sequence\n  When Skip strategy skips event N\n  Then event N+1 is processed next (gap, not reorder)\n  When Retry strategy retries event N\n  Then event N+1 waits until N succeeds or escalates to Fatal","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-14T11:19:12.043690936-08:00","updated_at":"2025-12-14T13:05:49.802747644-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-4tk","depends_on_id":"eventcore-017","type":"blocks","created_at":"2025-12-14T11:20:02.228180266-08:00","created_by":"daemon"}]}
{"id":"eventcore-522","content_hash":"880ad404b88b8a41f852f62633a722428de193f067cb1106793450f83aec1c9c","title":"Refactor: Consolidate validation predicates","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:08.077648564-08:00","updated_at":"2025-12-16T21:22:19.015696117-08:00","closed_at":"2025-12-16T21:22:19.015696117-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-522","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:07.172959197-08:00","created_by":"daemon"}]}
{"id":"eventcore-6zm","content_hash":"4aa11981a529076b843ae8d30a2078bf998effe8f5e55a4413f86a06b7f4ce00","title":"CRITICAL: Add logging for silent database poll errors in Postgres subscription","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:41:50.185808638-08:00","updated_at":"2025-12-17T10:42:51.509725793-08:00","closed_at":"2025-12-17T10:42:51.509725793-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-6zm","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-17T10:41:50.186726064-08:00","created_by":"daemon"}]}
{"id":"eventcore-7pg","content_hash":"b775194c2e5b3505c01af54a07cb60755755e35ffbce49c5ef9b52a407554d60","title":"Update I-017 tests to handle Result stream items","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T11:18:46.654892073-08:00","updated_at":"2025-12-15T09:30:13.983247991-08:00","closed_at":"2025-12-15T09:30:13.983247991-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-7pg","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-14T11:18:46.655735504-08:00","created_by":"daemon"}]}
{"id":"eventcore-7sc","content_hash":"350613b10f721161127fb214dea47c1aed3309bfddaaed52333fc5e7649306d6","title":"CRITICAL: Add logging for silent broadcast send failures in InMemoryEventStore","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:41:49.945585384-08:00","updated_at":"2025-12-17T10:42:51.491779414-08:00","closed_at":"2025-12-17T10:42:51.491779414-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-7sc","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-17T10:41:49.976499599-08:00","created_by":"daemon"}]}
{"id":"eventcore-8t2","content_hash":"2a52581e62cbb87316e49ef04b9a522a9d33fa4b61c0687a9e092aa8ab4ee704","title":"Document InMemoryEventStore limitations","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T13:16:55.841277314-08:00","updated_at":"2025-12-15T17:36:00.964571915-08:00","closed_at":"2025-12-15T17:36:00.964571915-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-8t2","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-13T13:16:55.842172067-08:00","created_by":"daemon"}]}
{"id":"eventcore-a43","content_hash":"d4f90af9618ca046ff5e75d5ba6486f2da0e827cfc174785c3b7552602c40ee6","title":"Add tracing/logging for subscription operations","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T13:16:45.894766862-08:00","updated_at":"2025-12-15T17:34:03.145594597-08:00","closed_at":"2025-12-15T17:34:03.145594597-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-a43","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-13T13:16:45.902737265-08:00","created_by":"daemon"}]}
{"id":"eventcore-aet","content_hash":"451c9ae7db9664d0c15a406c64ad9ea797acdd34d3cf50d92fa761346880bf4e","title":"Investigate: StreamVersion vs EventId for optimistic concurrency","description":"Currently StreamVersion is a monotonic counter (0, 1, 2...) used for optimistic concurrency. However, since EventId is UUIDv7 (time-ordered), we could potentially use the last event's EventId as the 'version' for conflict detection.\n\n**Questions to investigate:**\n1. Would comparing EventIds provide equivalent conflict detection to comparing StreamVersions?\n2. What are the trade-offs? (storage, comparison performance, semantics)\n3. Could this simplify the API by removing StreamVersion entirely?\n4. How do other event stores handle this? (EventStoreDB, Marten, etc.)\n\n**Context:**\n- StreamVersion currently starts at 0 for empty streams\n- Each append increments version by 1\n- EventId is UUIDv7 with embedded timestamp + randomness\n- Conflict detection compares expected vs actual version","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-06T22:19:47.689824218-08:00","updated_at":"2025-12-06T22:19:47.689824218-08:00","source_repo":".","labels":["api-design","investigation"]}
{"id":"eventcore-byx","content_hash":"e15cd4035b1c69ea0b155170f63de294a3d5eca7c177a93bd2cb889f536d635d","title":"Add test cases for subscription error scenarios","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T13:16:53.295467724-08:00","updated_at":"2025-12-15T14:58:52.952037706-08:00","closed_at":"2025-12-15T14:58:52.952037706-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-byx","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-13T13:16:53.296201452-08:00","created_by":"daemon"}]}
{"id":"eventcore-c30","content_hash":"41943c8cfa4c232ffe921ba6caeb9d1b7533461029e2d3e800027e52604bd590","title":"Change Stream\u003cItem = E\u003e to Stream\u003cItem = Result\u003cE, SubscriptionError\u003e\u003e","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T11:18:46.451044762-08:00","updated_at":"2025-12-15T09:30:13.95603627-08:00","closed_at":"2025-12-15T09:30:13.95603627-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-c30","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-14T11:18:46.453518667-08:00","created_by":"daemon"}]}
{"id":"eventcore-c47","content_hash":"ffdaa1e81afb2e9294f7b54e45ca7db837416f8cd466599ee757f9fd9070e090","title":"Refactor: Standardize SubscriptionQuery getter naming","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:15.153471126-08:00","updated_at":"2025-12-16T21:54:10.269558319-08:00","closed_at":"2025-12-16T21:54:10.269558319-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-c47","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:07.431880875-08:00","created_by":"daemon"}]}
{"id":"eventcore-cww","content_hash":"4d3a7473631f0c4857c3ebde41b4f273de44d1ca90c63b38a3a77a6c6c650beb","title":"Refactor: Consolidate test event types within crates","description":"","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-16T14:49:22.614889646-08:00","updated_at":"2025-12-17T07:31:50.719649337-08:00","closed_at":"2025-12-17T07:31:50.719649337-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-cww","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:14.306681865-08:00","created_by":"daemon"}]}
{"id":"eventcore-fbj","content_hash":"0ed65f89182841d9a004e4d5c02d5edc87f36787e6f380b8c550c84531c57f99","title":"Refactor: Add fluent StreamWrites API","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T14:49:15.390997209-08:00","updated_at":"2025-12-16T20:48:38.067354754-08:00","closed_at":"2025-12-16T20:48:38.067354754-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-fbj","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:07.039331683-08:00","created_by":"daemon"}]}
{"id":"eventcore-ihm","content_hash":"db4b72ecf365caf4c03fb6a09355261719401c817949b44875228eaefa0f18a7","title":"Glob Pattern Matching for Subscriptions","description":"Implements POSIX glob pattern matching for SubscriptionQuery per ADR-017 and ARCHITECTURE.md v1.6. Enables filtering subscriptions using wildcard patterns like `account-*` or `order-[0-9]*`.\n\n**Core Components:**\n- StreamPattern type that permits glob metacharacters (*, ?, [, ])\n- SubscriptionQuery::filter_stream_pattern(StreamPattern) method\n- POSIX glob matching via `glob` crate (or similar)\n\n**Design Decisions (from ARCHITECTURE.md):**\n- Distinct type: StreamPattern vs StreamPrefix (literals) - type system makes intent explicit\n- Reserved characters in StreamId/StreamPrefix enable unambiguous pattern matching\n- POSIX glob over regex: simpler, sufficient, safer (no catastrophic backtracking)\n\n**Depends on:**\n- eventcore-017 (subscription foundation) - must be complete\n- StreamId/StreamPrefix character restrictions - must be implemented first","acceptance_criteria":"Feature: Developer filters subscriptions with glob patterns\n\nScenario: Developer creates StreamPattern with wildcards\n  Given developer imports StreamPattern\n  When developer writes StreamPattern::new(\"account-*\")\n  Then pattern is created successfully\n  And pattern contains the wildcard character\n\nScenario: Developer filters subscription by glob pattern\n  Given InMemoryEventStore with streams: account-123, account-456, order-789\n  When developer calls subscribe(SubscriptionQuery::all().filter_stream_pattern(StreamPattern::new(\"account-*\")))\n  Then only events from account-123 and account-456 are delivered\n  And events from order-789 are filtered out\n\nScenario: Developer uses single-character wildcard\n  Given streams: user-a, user-b, user-ab, admin-x\n  When developer filters with StreamPattern::new(\"user-?\")\n  Then only user-a and user-b match (single char after prefix)\n  And user-ab does not match (two chars)\n\nScenario: Developer uses character class\n  Given streams: order-1, order-2, order-a, order-b\n  When developer filters with StreamPattern::new(\"order-[0-9]\")\n  Then order-1 and order-2 match\n  And order-a and order-b do not match\n\nScenario: Developer distinguishes pattern from prefix\n  Given StreamPrefix for literal matching\n  And StreamPattern for wildcard matching\n  When developer attempts StreamPrefix::new(\"account-*\")\n  Then error is returned (glob chars forbidden in prefix)\n  When developer uses StreamPattern::new(\"account-*\")\n  Then pattern is created successfully","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-10T17:34:20.223782216-08:00","updated_at":"2025-12-10T17:34:41.346110628-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-ihm","depends_on_id":"eventcore-017","type":"blocks","created_at":"2025-12-10T17:35:11.149021106-08:00","created_by":"daemon"}]}
{"id":"eventcore-mtj","content_hash":"8b76a521cbf7c6291236c9ce1dd3f5900f4bc12044d615ff32d36df355b6535d","title":"Refactor: Decompose subscribe() methods","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T14:49:07.954060713-08:00","updated_at":"2025-12-16T16:53:40.459920244-08:00","closed_at":"2025-12-16T16:53:40.459920244-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-mtj","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:06.890792071-08:00","created_by":"daemon"}]}
{"id":"eventcore-nu9","content_hash":"e2aff31e32c18b6569dea2565257b21ba55cac3e02c875a2bccedc7492fce00d","title":"CRITICAL: Mark unimplemented Projector/Checkpoint sections in ARCHITECTURE.md as Planned","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-17T10:41:50.297248825-08:00","updated_at":"2025-12-17T10:42:51.520872499-08:00","closed_at":"2025-12-17T10:42:51.520872499-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-nu9","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-17T10:41:50.29820461-08:00","created_by":"daemon"}]}
{"id":"eventcore-spt","content_hash":"1e487cb6a38c3fbf08e502a08cee5d11531c12b5f201fadee53ac5cda129462c","title":"Refactor: Document sequence deduplication strategy","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-16T14:49:15.04197046-08:00","updated_at":"2025-12-16T21:34:53.709933235-08:00","closed_at":"2025-12-16T21:34:53.709933235-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-spt","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:07.298047181-08:00","created_by":"daemon"}]}
{"id":"eventcore-utr","content_hash":"4fe12b75cc599207144fba0e516c1146543a122f6d4a8d5f819c3adc22ae3ece","title":"Fix InMemoryEventStore subscription to deliver events appended after subscription creation","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T16:21:52.398582431-08:00","updated_at":"2025-12-14T23:44:11.887282401-08:00","closed_at":"2025-12-14T23:44:11.887282401-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-utr","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-14T16:21:52.400824615-08:00","created_by":"daemon"},{"issue_id":"eventcore-utr","depends_on_id":"eventcore-0ex","type":"blocks","created_at":"2025-12-14T23:08:54.347493138-08:00","created_by":"daemon"}]}
{"id":"eventcore-wtz","content_hash":"a568d735423abff985902153aa3196e5bcfdae57bafb93dc336b189d3cfc5f81","title":"Refactor: Extract implementation-local filtering helpers","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T14:49:07.839083089-08:00","updated_at":"2025-12-16T16:48:45.976626949-08:00","closed_at":"2025-12-16T16:48:45.976626949-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-wtz","depends_on_id":"eventcore-017","type":"parent-child","created_at":"2025-12-16T15:29:06.770451716-08:00","created_by":"daemon"}]}
{"id":"eventcore-zw6","content_hash":"3ee22ec47341eaaefe980b30a4a8a1b10fc11b2656735667c752e52d3077eae5","title":"Add subscription usage examples to README","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T13:16:50.692112217-08:00","updated_at":"2025-12-15T17:35:04.643704368-08:00","closed_at":"2025-12-15T17:35:04.643704368-08:00","source_repo":".","dependencies":[{"issue_id":"eventcore-zw6","depends_on_id":"eventcore-017","type":"discovered-from","created_at":"2025-12-13T13:16:50.702764819-08:00","created_by":"daemon"}]}
{"id":"eventcore-zy4","content_hash":"d0b7d4f4516d97bae43472f179ac0bcd00e703172951015ba6b79057b2e9b2a3","title":"Switch to cargo-nextest for faster test execution","description":"Replace standard cargo test with cargo-nextest across:\n- Local development (AGENTS.md documentation)\n- Pre-commit hooks (.pre-commit-config.yaml)\n- CI workflow (.github/workflows/ci.yml)\n\nBenefits:\n- Faster parallel test execution\n- Better test output formatting\n- Improved failure reporting\n\nDependencies:\n- Add cargo-nextest to dev tooling\n- Update all test invocations\n- Verify compatibility with existing test suite","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-08T16:46:19.317793502-08:00","updated_at":"2025-11-09T22:21:43.665482497-08:00","closed_at":"2025-11-09T22:21:43.665482497-08:00","source_repo":"."}
