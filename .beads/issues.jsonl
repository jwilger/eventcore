{"id":"I-001","title":"Single-Stream Command End-to-End","description":"Enable library consumer to create and execute a complete single-stream command with validated domain types, proper error handling, and in-memory event storage. Provides working, testable command execution system.","design":"**Domain Types**: StreamId, EventId, CorrelationId, CausationId (nutype)\n**Error Handling**: Structured hierarchy (EventStoreError, CommandError, ValidationError, ConcurrencyError)\n**Storage**: InMemoryEventStore with optimistic concurrency\n**Command System**: CommandStreams and CommandLogic traits (manual, no macro)\n**Executor**: CommandExecutor orchestrating read → apply → handle → write (NO retry)","acceptance_criteria":"Feature: Developer executes complete single-stream command end-to-end\n\nScenario 1: Developer implements and executes bank account command\n- Creates BankAccount command with StreamId using nutype\n- Implements CommandLogic with apply() and handle()\n- Creates InMemoryEventStore\n- Executes Deposit(account_id, amount: 100)\n- Command succeeds\n- AccountDeposited event is stored with correct metadata\n- Developer can read events from the stream\n- Event contains amount of 100\n\nScenario 2: Developer handles business rule violations with proper errors\n- Account has balance of 50\n- Executes Withdraw command with amount 100\n- CommandError::BusinessRuleViolation is returned\n- Error message explains insufficient funds: balance 50, withdrawal 100\n- Error includes context (account_id, current balance, attempted withdrawal)\n- State is reconstructed via apply() to determine current balance\n\nScenario 3: Developer handles version conflict manually\n- Executes two concurrent Deposit commands on same account\n- Both commands read account at version 0\n- First command writes event, advancing to version 1\n- Second command attempts write expecting version 1\n- ConcurrencyError is returned to developer\n- Developer must handle retry manually (or wait for I-002)\n- No automatic retry occurs\n- Developer can inspect error details (expected vs actual version)","status":"in_progress","priority":1,"issue_type":"feature","assignee":"jwilger","created_at":"2025-10-22T09:57:20.327343363-07:00","updated_at":"2025-10-22T21:07:57.039415768-07:00"}
{"id":"I-002","title":"Automatic Retry with Sensible Defaults","description":"Add automatic retry on version conflicts so developers don't have to handle ConcurrencyError manually. Use hardcoded sensible defaults (5 retries, exponential backoff with jitter) that work for most cases.","design":"**Retry Logic**: Hardcoded exponential backoff (10ms, 20ms, 40ms, 80ms, 160ms), max 5 attempts, jitter to prevent thundering herd\n**Observability**: Basic logging of retry attempts and outcomes\n**Behavior**: ConcurrencyError triggers automatic retry instead of being returned to developer","acceptance_criteria":"See docs/PLANNING.md I-002 acceptance criteria","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.383583474-07:00","updated_at":"2025-10-22T10:06:25.473189145-07:00","dependencies":[{"issue_id":"I-002","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:52.395229329-07:00","created_by":"daemon"}]}
{"id":"I-003","title":"Configurable Retry Policies","description":"Enable library consumers to customize retry behavior for their specific workloads and observe retry patterns through metrics and tracing. RetryPolicy configuration with custom max attempts, backoff strategies, and advanced observability.","design":"**RetryPolicy Configuration**: Builder pattern for custom configuration, configurable max attempts/backoff strategies (exponential/linear/fixed)\n**Advanced Observability**: Integration with tracing crate, metrics hooks compatible with Prometheus, structured log format\n**Testing Utilities**: RetryPolicy with max_attempts=0 for disabling retry in tests, chaos testing support","acceptance_criteria":"See docs/PLANNING.md I-003 acceptance criteria","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.635170763-07:00","updated_at":"2025-10-22T10:06:25.475330131-07:00","dependencies":[{"issue_id":"I-003","depends_on_id":"I-002","type":"blocks","created_at":"2025-10-22T09:59:52.645026809-07:00","created_by":"daemon"}]}
{"id":"I-004","title":"Multi-Stream Atomic Commands","description":"Enable library consumers to create commands that atomically read from and write to multiple event streams - THE core value proposition of EventCore. Commands declare multiple streams, read from all declared streams, and write to multiple streams atomically with all-or-nothing semantics.","design":"**Multi-Stream Support**: Commands declare multiple stream IDs, executor reads all declared streams, state reconstruction from events across multiple streams, atomic write to all streams with per-stream version checking\n**Enhanced InMemoryEventStore**: Atomic append across multiple streams, version checking for all streams in single operation, all-or-nothing guarantee\n**Example**: TransferMoney command demonstrating atomic debit/credit","acceptance_criteria":"See docs/PLANNING.md I-004 acceptance criteria","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:52.878747571-07:00","updated_at":"2025-10-22T10:06:25.477399869-07:00","dependencies":[{"issue_id":"I-004","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:52.888791467-07:00","created_by":"daemon"},{"issue_id":"I-004","depends_on_id":"I-002","type":"blocks","created_at":"2025-10-22T09:59:52.890959478-07:00","created_by":"daemon"}]}
{"id":"I-005","title":"PostgreSQL Production Backend","description":"Enable library consumers to use production-ready PostgreSQL storage with ACID transactions for multi-stream atomicity. Separate eventcore-postgres crate implementing EventStore trait.","design":"**PostgreSQL Adapter**: Separate crate implementing EventStore trait, connection pooling (sqlx), ACID transaction support, JSON event serialization, schema migrations\n**Event Schema**: Events table with UUID primary keys, stream ID/version with unique constraint, JSONB event type/data/metadata, timestamp tracking, optimized indexes\n**Integration Tests**: Real PostgreSQL tests via Docker Compose, multi-stream atomicity with ACID, concurrent command tests","acceptance_criteria":"See docs/PLANNING.md I-005 acceptance criteria","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-22T09:59:53.147969784-07:00","updated_at":"2025-10-22T10:06:25.479247198-07:00","dependencies":[{"issue_id":"I-005","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:53.158076523-07:00","created_by":"daemon"},{"issue_id":"I-005","depends_on_id":"I-004","type":"blocks","created_at":"2025-10-22T09:59:53.160209793-07:00","created_by":"daemon"}]}
{"id":"I-006","title":"Command Derive Macro","description":"Eliminate infrastructure boilerplate by auto-generating CommandStreams trait implementation from #[stream] field attributes. Developers use #[derive(Command)] to generate all infrastructure code, leaving only domain logic to implement.","design":"**Procedural Macro**: Separate eventcore-macros crate with proc-macro, #[derive(Command)] generates CommandStreams trait, #[stream] field attribute marks stream fields, phantom types for compile-time stream access control\n**Developer Experience**: Before ~30 lines infrastructure, after ~5 lines with derive, focus only on apply/handle methods\n**Testing**: Macro expansion tests with trybuild, integration tests comparing macro vs manual implementation","acceptance_criteria":"See docs/PLANNING.md I-006 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.39983429-07:00","updated_at":"2025-10-22T10:06:25.48148275-07:00","dependencies":[{"issue_id":"I-006","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:53.410122534-07:00","created_by":"daemon"},{"issue_id":"I-006","depends_on_id":"I-004","type":"blocks","created_at":"2025-10-22T09:59:53.412440986-07:00","created_by":"daemon"}]}
{"id":"I-007","title":"Dynamic Stream Discovery","description":"Enable commands to discover additional streams at runtime based on state, supporting workflows where stream requirements depend on runtime data. StreamResolver trait allowing commands to examine initial state and declare additional streams with full atomicity maintained.","design":"**StreamResolver Trait**: Optional trait for commands with state-dependent streams, resolve_additional_streams(state) method, executor support for multi-pass discovery, incremental re-reading optimization\n**Discovery Integration**: Static streams declared with #[stream], dynamic streams discovered via resolver, all streams participate in atomicity, deduplication prevents re-reading same stream\n**Example**: ProcessPayment command discovering payment method streams","acceptance_criteria":"See docs/PLANNING.md I-007 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.677539911-07:00","updated_at":"2025-10-22T10:06:25.483919344-07:00","dependencies":[{"issue_id":"I-007","depends_on_id":"I-004","type":"blocks","created_at":"2025-10-22T09:59:53.68792184-07:00","created_by":"daemon"},{"issue_id":"I-007","depends_on_id":"I-006","type":"blocks","created_at":"2025-10-22T09:59:53.689909474-07:00","created_by":"daemon"}]}
{"id":"I-008","title":"Basic Event Subscriptions","description":"Enable developers to subscribe to event streams and process events in order. Core subscription mechanism WITHOUT checkpointing (I-009 adds that). EventSubscription trait allowing consumers to subscribe to streams and process events using poll-based or callback-based approach.","design":"**EventSubscription Trait**: subscribe(stream_ids) method returning event iterator/stream, delivers events in stream order, works with PostgreSQL and in-memory backends\n**Subscription Features**: Subscribe to one or more streams with pattern matching, process events to build read models, events delivered in order within each stream\n**Example**: AccountBalance projection showing simple read model (not restart-safe yet)","acceptance_criteria":"See docs/PLANNING.md I-008 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:53.969674847-07:00","updated_at":"2025-10-22T10:06:25.485972048-07:00","dependencies":[{"issue_id":"I-008","depends_on_id":"I-005","type":"blocks","created_at":"2025-10-22T09:59:53.979602684-07:00","created_by":"daemon"}]}
{"id":"I-009","title":"Checkpointing for Subscriptions","description":"Add checkpoint storage and resume capability to subscriptions, enabling reliable projection rebuilding and restart safety. Checkpoint persistence allowing subscriptions to resume from last processed position after restart, making projections production-ready.","design":"**Checkpoint Storage**: save_checkpoint(subscription_id, position) method, load_checkpoint(subscription_id) returns last saved position, checkpoint stored alongside events, automatic checkpoint advancement\n**Resume from Checkpoint**: On restart load last checkpoint, events delivered from checkpoint position + 1, projection rebuilds only new events\n**Projection Rebuilding**: Reset checkpoint to version 0 for complete rebuild, replay all historical events","acceptance_criteria":"See docs/PLANNING.md I-009 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:54.244346703-07:00","updated_at":"2025-10-22T10:06:25.487856055-07:00","dependencies":[{"issue_id":"I-009","depends_on_id":"I-008","type":"blocks","created_at":"2025-10-22T09:59:54.254509733-07:00","created_by":"daemon"}]}
{"id":"I-010","title":"Chaos Testing Infrastructure","description":"Enable robust testing by injecting failures (read errors, write errors, version conflicts) into in-memory store. Chaos mode for InMemoryEventStore allowing developers to test error handling paths systematically.","design":"**Chaos Configuration**: Configurable failure injection rates, read failures/write failures/version conflict injection, deterministic chaos for reproducible tests","acceptance_criteria":"See docs/PLANNING.md I-010 acceptance criteria","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.516254533-07:00","updated_at":"2025-10-22T10:06:25.4896694-07:00","dependencies":[{"issue_id":"I-010","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:54.518752119-07:00","created_by":"daemon"}]}
{"id":"I-011","title":"Performance Benchmarking Suite","description":"Establish performance baselines and track regressions using Criterion.rs benchmarks. Comprehensive benchmark suite measuring throughput, latency, and memory usage for key operations.","design":"**Benchmark Suite**: Single-stream command execution, multi-stream command execution, event append throughput, state reconstruction performance, PostgreSQL vs in-memory comparison\n**Criterion.rs**: Reports ops/sec, latency percentiles (P50, P95, P99), results stored for regression tracking","acceptance_criteria":"See docs/PLANNING.md I-011 acceptance criteria","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:54.806895386-07:00","updated_at":"2025-10-22T10:06:25.491823434-07:00","dependencies":[{"issue_id":"I-011","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:54.81676785-07:00","created_by":"daemon"},{"issue_id":"I-011","depends_on_id":"I-004","type":"blocks","created_at":"2025-10-22T09:59:54.818896767-07:00","created_by":"daemon"},{"issue_id":"I-011","depends_on_id":"I-005","type":"blocks","created_at":"2025-10-22T09:59:54.820992753-07:00","created_by":"daemon"}]}
{"id":"I-012","title":"Snapshot Support for Performance","description":"Optimize state reconstruction for long-lived streams by periodically saving snapshots and starting reconstruction from snapshot instead of version 0. Comes AFTER I-011 because we need performance data to determine if snapshots are necessary and what snapshot frequency makes sense.","design":"**SnapshotStore Trait**: save_snapshot(stream_id, version, state) method, load_snapshot(stream_id) returns (version, state), snapshots stored alongside events, automatic snapshot creation at configurable intervals\n**Executor Integration**: Check for snapshot before reading events, if snapshot exists start from snapshot version, apply only events after snapshot\n**Benchmark-Driven**: Use I-011 benchmark data to determine optimal snapshot frequency","acceptance_criteria":"See docs/PLANNING.md I-012 acceptance criteria","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-22T09:59:55.082406342-07:00","updated_at":"2025-10-22T10:06:25.493672046-07:00","dependencies":[{"issue_id":"I-012","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:55.092451654-07:00","created_by":"daemon"},{"issue_id":"I-012","depends_on_id":"I-011","type":"blocks","created_at":"2025-10-22T09:59:55.094589257-07:00","created_by":"daemon"}]}
{"id":"I-013","title":"require! Macro","description":"Provide ergonomic macro for business rule validation with early return, making validation code concise and readable. require! macro that checks conditions and returns CommandError::BusinessRuleViolation on failure. Simpler than emit! (just generates early return with error).","design":"**require! Macro**: Simple condition checking with early return, returns CommandError::BusinessRuleViolation on failure, descriptive error messages from validation expressions, format string support\n**Implementation**: Declarative macro (not proc-macro), expands to if !condition { return Err(...) }, works in any function returning Result\u003c_, CommandError\u003e","acceptance_criteria":"See docs/PLANNING.md I-013 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.382858264-07:00","updated_at":"2025-10-22T10:06:25.495576203-07:00","dependencies":[{"issue_id":"I-013","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:55.393944933-07:00","created_by":"daemon"}]}
{"id":"I-014","title":"emit! Macro","description":"Provide type-safe event emission macro with compile-time verification that events are emitted to declared streams. emit! macro that works with phantom types from derive macro to provide compile-time safety. More complex than require! - must work with phantom types generated by #[derive(Command)].","design":"**emit! Macro**: Compile-time verification that stream is declared in command, works with phantom types from #[derive(Command)], concise syntax for event emission, IDE autocomplete support\n**Type Safety**: Phantom types ensure events only emitted to declared streams, compile error if emitting to undeclared stream\n**Integration**: Works with phantom types from derive macro, stream names from derive macro available to emit! macro","acceptance_criteria":"See docs/PLANNING.md I-014 acceptance criteria","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T09:59:55.698240824-07:00","updated_at":"2025-10-22T10:06:25.498102177-07:00","dependencies":[{"issue_id":"I-014","depends_on_id":"I-006","type":"blocks","created_at":"2025-10-22T09:59:55.717324222-07:00","created_by":"daemon"}]}
{"id":"I-015","title":"Documentation Completeness Audit","description":"Audit and ensure completeness, consistency, and quality of documentation written incrementally throughout I-001 to I-014. NOT 'write all documentation at the end' - each increment includes its own documentation. This ensures documentation is complete, consistent across increments, and ready for library release.","design":"**Completeness Audit**: Verify each increment has Getting Started section, check API docs completeness, ensure examples directory has working code\n**Consistency Audit**: Terminology consistency, code style consistency in examples, accurate cross-references\n**Quality Audit**: Can new developer implement first command in \u003c30 min? Are common issues documented? Are concepts explained for newcomers?","acceptance_criteria":"See docs/PLANNING.md I-015 acceptance criteria","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:55.9972299-07:00","updated_at":"2025-10-22T10:06:25.500078486-07:00","dependencies":[{"issue_id":"I-015","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:56.007308554-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-002","type":"blocks","created_at":"2025-10-22T09:59:56.009464365-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-003","type":"blocks","created_at":"2025-10-22T09:59:56.01170298-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-004","type":"blocks","created_at":"2025-10-22T09:59:56.013797658-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-005","type":"blocks","created_at":"2025-10-22T09:59:56.015716896-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-006","type":"blocks","created_at":"2025-10-22T09:59:56.017720808-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-007","type":"blocks","created_at":"2025-10-22T09:59:56.019802867-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-008","type":"blocks","created_at":"2025-10-22T09:59:56.021853841-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-009","type":"blocks","created_at":"2025-10-22T09:59:56.023919626-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-010","type":"blocks","created_at":"2025-10-22T09:59:56.025929586-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-011","type":"blocks","created_at":"2025-10-22T09:59:56.027865114-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-012","type":"blocks","created_at":"2025-10-22T09:59:56.029888021-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-013","type":"blocks","created_at":"2025-10-22T09:59:56.031987839-07:00","created_by":"daemon"},{"issue_id":"I-015","depends_on_id":"I-014","type":"blocks","created_at":"2025-10-22T09:59:56.034210146-07:00","created_by":"daemon"}]}
{"id":"I-016","title":"Error Message Consistency Audit","description":"Audit and ensure consistency, clarity, and actionability of error messages written incrementally throughout I-001 to I-014. NOT 'add error messages at the end' - error quality is foundational from I-001. This ensures error messages are consistent in format, provide appropriate context, and are actionable across all increments.","design":"**Consistency Audit**: Error message format consistency, error type usage consistency, context inclusion patterns, action suggestion patterns\n**Clarity Audit**: Are error messages understandable? Do messages explain WHAT failed and WHY? Are technical terms explained?\n**Actionability Audit**: Does each error suggest next steps? Are links to documentation included? Do validation errors show actual vs expected values?","acceptance_criteria":"See docs/PLANNING.md I-016 acceptance criteria","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-22T09:59:56.352815929-07:00","updated_at":"2025-10-22T10:06:25.502011244-07:00","dependencies":[{"issue_id":"I-016","depends_on_id":"I-001","type":"blocks","created_at":"2025-10-22T09:59:56.362671823-07:00","created_by":"daemon"},{"issue_id":"I-016","depends_on_id":"I-015","type":"blocks","created_at":"2025-10-22T09:59:56.365070485-07:00","created_by":"daemon"}]}
